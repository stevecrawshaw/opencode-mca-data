DuckDB documentation overview. Connection, Client APIs (CLI Java Python R WebAssembly), SQL, Installation. ADBC API enables portable code between database systems using Arrow for data transfer. DuckDB's driver supports ADBC version 0.7. Database: DatabaseNew(AdbcDatabase *database, AdbcError *error): Allocates a new database. DatabaseSetOption(AdbcDatabase *database, const char *key, const char *value, AdbcError *error): Sets a database option. DatabaseInit(AdbcDatabase *database, AdbcError *error): Initializes the database. DatabaseRelease(AdbcDatabase *database, AdbcError *error): Destroys the database. Connection: ConnectionNew(AdbcConnection*, AdbcError*): Allocates a new connection. ConnectionSetOption(AdbcConnection*, const char*, const char*, AdbcError*): Sets a connection option before initialization. ConnectionInit(AdbcConnection*, AdbcDatabase*, AdbcError*): Initializes the connection. ConnectionRelease(AdbcConnection*, AdbcError*): Destroys the connection. ConnectionGetObjects(AdbcConnection*, int, const char*, const char*, const char*, const char**, const char*, ArrowArrayStream*, AdbcError*): Gets a hierarchical view of database objects as an ArrowArrayStream. ConnectionGetTableSchema(AdbcConnection*, const char*, const char*, const char*, ArrowSchema*, AdbcError*): Gets the Arrow schema of a table. ConnectionGetTableTypes(AdbcConnection*, ArrowArrayStream*, AdbcError*): Gets a list of table types. ConnectionCommit(AdbcConnection*, AdbcError*): Commits pending transactions. ConnectionRollback(AdbcConnection*, AdbcError*): Rolls back pending transactions. Statement: StatementNew(AdbcConnection*, AdbcStatement*, AdbcError*): Creates a new statement. StatementRelease(AdbcStatement*, AdbcError*): Destroys a statement. StatementSetOption(AdbcStatement*, const char*, const char*, AdbcError*): Sets a statement option. StatementSetSqlQuery(AdbcStatement*, const char*, AdbcError*): Sets the SQL query to execute. StatementSetSubstraitPlan(AdbcStatement*, const uint8_t*, size_t, AdbcError*): Sets a Substrait plan to execute. StatementExecuteQuery(AdbcStatement*, ArrowArrayStream*, int64_t*, AdbcError*): Executes a query and gets the results. StatementPrepare(AdbcStatement*, AdbcError*): Prepares a statement for multiple executions. StatementBindStream(AdbcStatement*, ArrowArrayStream*, AdbcError*): Binds an Arrow stream for bulk insertion/prepared statements. Example: AdbcDatabaseSetOption(&adbc_database, "path", "test.db", &adbc_error) C API for DuckDB. `duckdb_open(path, *out_database)`: Open DB. `duckdb_open_ext(path, *out_database, config, *out_error)`: Extended open. `duckdb_close(*database)`: Close DB. `duckdb_connect(database, *out_connection)`: Connect. `duckdb_interrupt(connection)`: Interrupt query. `duckdb_query_progress(connection)`: Get progress (-1 if no progress). `duckdb_disconnect(*connection)`: Disconnect. `duckdb_library_version()`: Get version. Config: `duckdb_create_config(*out_config)`, `duckdb_config_count()`, `duckdb_get_config_flag(index, **out_name, **out_description)`, `duckdb_set_config(config, name, option)`, `duckdb_destroy_config(*config)`. Query: `duckdb_query(connection, query, *out_result)`, `duckdb_destroy_result(*result)`, `duckdb_column_name(result, col)`, `duckdb_column_type(result, col)`, `duckdb_result_statement_type(result)`, `duckdb_column_logical_type(result, col)`, `duckdb_column_count(result)`, `duckdb_row_count(result)`, `duckdb_rows_changed(result)`, `duckdb_column_data(result, col)`, `duckdb_nullmask_data(result, col)`, `duckdb_result_error(result)`, `duckdb_result_error_type(result)`. Result Functions: `duckdb_result_get_chunk(result, chunk_index)`, `duckdb_result_is_streaming(result)`, `duckdb_result_chunk_count(result)`, `duckdb_result_return_type(result)`. Safe Fetch: `duckdb_value_boolean(result, col, row)`, `duckdb_value_int8(result, col, row)`, `duckdb_value_int16(result, col, row)`, `duckdb_value_int32(result, col, row)`, `duckdb_value_int64(result, col, row)`, `duckdb_value_hugeint(result, col, row)`, `duckdb_value_uhugeint(result, col, row)`, `duckdb_value_decimal(result, col, row)`, `duckdb_value_uint8(result, col, row)`, `duckdb_value_uint16(result, col, row)`, `duckdb_value_uint32(result, col, row)`, `duckdb_value_uint64(result, col, row)`, `duckdb_value_float(result, col, row)`, `duckdb_value_double(result, col, row)`, `duckdb_value_date(result, col, row)`, `duckdb_value_time(result, col, row)`, `duckdb_value_timestamp(result, col, row)`, `duckdb_value_interval(result, col, row)`, `duckdb_value_varchar(result, col, row)`, `duckdb_value_string(result, col, row)`, `duckdb_value_varchar_internal(result, col, row)`, `duckdb_value_string_internal(result, col, row)`, `duckdb_value_blob(result, col, row)`, `duckdb_value_is_null(result, col, row)`. Helpers: `duckdb_malloc(size)`, `duckdb_free(ptr)`, `duckdb_vector_size()`, `duckdb_string_is_inlined(string)`, `duckdb_string_t_length(string)`, `duckdb_string_t_data(*string)`. Datetime: `duckdb_from_date(date)`, `duckdb_to_date(date)`, `duckdb_is_finite_date(date)`, `duckdb_from_time(time)`, `duckdb_create_time_tz(micros, offset)`, `duckdb_from_time_tz(micros)`, `duckdb_to_time(time)`, `duckdb_from_timestamp(ts)`, `duckdb_to_timestamp(ts)`, `duckdb_is_finite_timestamp(ts)`. Hugeint: `duckdb_hugeint_to_double(val)`, `duckdb_double_to_hugeint(val)`. Uhugeint: `duckdb_uhugeint_to_double(val)`, `duckdb_double_to_uhugeint(val)`. Decimal: `duckdb_double_to_decimal(val, width, scale)`, `duckdb_decimal_to_double(val)`. Prepared Statements: `duckdb_prepare(connection, query, *out_prepared_statement)`, `duckdb_destroy_prepare(*prepared_statement)`, `duckdb_prepare_error(prepared_statement)`, `duckdb_nparams(prepared_statement)`, `duckdb_parameter_name(prepared_statement, index)`, `duckdb_param_type(prepared_statement, param_idx)`, `duckdb_clear_bindings(prepared_statement)`, `duckdb_prepared_statement_type(statement)`. Bind: `duckdb_bind_value(prepared_statement, param_idx, val)`, `duckdb_bind_parameter_index(prepared_statement, *param_idx_out, name)`, `duckdb_bind_boolean(prepared_statement, param_idx, val)`, `duckdb_bind_int8(prepared_statement, param_idx, val)`, `duckdb_bind_int16(prepared_statement, param_idx, val)`, `duckdb_bind_int32(prepared_statement, param_idx, val)`, `duckdb_bind_int64(prepared_statement, param_idx, val)`, `duckdb_bind_hugeint(prepared_statement, param_idx, val)`, `duckdb_bind_uhugeint(prepared_statement, param_idx, val)`, `duckdb_bind_decimal(prepared_statement, param_idx, val)`, `duckdb_bind_uint8(prepared_statement, param_idx, val)`, `duckdb_bind_uint16(prepared_statement, param_idx, val)`, `duckdb_bind_uint32(prepared_statement, param_idx, val)`, `duckdb_bind_uint64(prepared_statement, param_idx, val)`, `duckdb_bind_float(prepared_statement, param_idx, val)`, `duckdb_bind_double(prepared_statement, param_idx, val)`, `duckdb_bind_date(prepared_statement, param_idx, val)`, `duckdb_bind_time(prepared_statement, param_idx, val)`, `duckdb_bind_timestamp(prepared_statement, param_idx, val)`, `duckdb_bind_timestamp_tz(prepared_statement, param_idx, val)`, `duckdb_bind_interval(prepared_statement, param_idx, val)`, `duckdb_bind_varchar(prepared_statement, param_idx, val)`, `duckdb_bind_varchar_length(prepared_statement, param_idx, val, length)`, `duckdb_bind_blob(prepared_statement, param_idx, data, length)`, `duckdb_bind_null(prepared_statement, param_idx)`. Execute: `duckdb_execute_prepared(prepared_statement, *out_result)`, `duckdb_execute_prepared_streaming(prepared_statement, *out_result)`. Extract: `duckdb_extract_statements(connection, query, *out_extracted_statements)`, `duckdb_prepare_extracted_statement(connection, extracted_statements, index, *out_prepared_statement)`, `duckdb_extract_statements_error(extracted_statements)`, `duckdb_destroy_extracted(*extracted_statements)`. Pending: `duckdb_pending_prepared(prepared_statement, *out_result)`, `duckdb_pending_prepared_streaming(prepared_statement, *out_result)`, `duckdb_destroy_pending(*pending_result)`, `duckdb_pending_error(pending_result)`, `duckdb_pending_execute_task(pending_result)`, `duckdb_pending_execute_check_state(pending_result)`, `duckdb_execute_pending(pending_result, *out_result)`, `duckdb_pending_execution_is_finished(pending_state)`. Value Interface: `duckdb_destroy_value(*value)`, `duckdb_create_varchar(text)`, `duckdb_create_varchar_length(text, length)`, `duckdb_create_bool(input)`, `duckdb_create_int8(input)`, `duckdb_create_uint8(input)`, `duckdb_create_int16(input)`, `duckdb_create_uint16(input)`, `duckdb_create_int32(input)`, `duckdb_create_uint32(input)`, `duckdb_create_uint64(input)`, `duckdb_create_int64(val)`, `duckdb_create_hugeint(input)`, `duckdb_create_uhugeint(input)`, `duckdb_create_float(input)`, `duckdb_create_double(input)`, `duckdb_create_date(input)`, `duckdb_create_time(input)`, `duckdb_create_time_tz_value(value)`, `duckdb_create_timestamp(input)`, `duckdb_create_interval(input)`, `duckdb_create_blob(data, length)`, `duckdb_get_bool(val)`, `duckdb_get_int8(val)`, `duckdb_get_uint8(val)`, `duckdb_get_int16(val)`, `duckdb_get_uint16(val)`, `duckdb_get_int32(val)`, `duckdb_get_uint32(val)`, `duckdb_get_int64(val)`, `duckdb_get_uint64(val)`, `duckdb_get_hugeint(val)`, `duckdb_get_uhugeint(val)`, `duckdb_get_float(val)`, `duckdb_get_double(val)`, `duckdb_get_date(val)`, `duckdb_get_time(val)`, `duckdb_get_time_tz(val)`, `duckdb_get_timestamp(val)`, `duckdb_get_interval(val)`, `duckdb_get_value_type(val)`, `duckdb_get_blob(val)`, `duckdb_get_varchar(value)`, `duckdb_create_struct_value(type, *values)`, `duckdb_create_list_value(type, *values, value_count)`, `duckdb_create_array_value(type, *values, value_count)`, `duckdb_get_map_size(value)`, `duckdb_get_map_key(value, index)`, `duckdb_get_map_value(value, index)`. Logical Type: `duckdb_create_logical_type(type)`, `duckdb_logical_type_get_alias(type)`, `duckdb_logical_type_set_alias(type, alias)`, `duckdb_create_list_type(type)`, `duckdb_create_array_type(type, array_size)`, `duckdb_create_map_type(key_type, value_type)`, `duckdb_create_union_type(*member_types, *member_names, member_count)`, `duckdb_create_struct_type(*member_types, *member_names, member_count)`, `duckdb_create_enum_type(*member_names, member_count)`, `duckdb_create_decimal_type(width, scale)`, `duckdb_get_type_id(type)`, `duckdb_decimal_width(type)`, `duckdb_decimal_scale(type)`, `duckdb_decimal_internal_type(type)`, `duckdb_enum_internal_type(type)`, `duckdb_enum_dictionary_size(type)`, `duckdb_enum_dictionary_value(type, index)`, `duckdb_list_type_child_type(type)`, `duckdb_array_type_child_type(type)`, `duckdb_array_type_array_size(type)`, `duckdb_map_type_key_type(type)`, `duckdb_map_type_value_type(type)`, `duckdb_struct_type_child_count(type)`, `duckdb_struct_type_child_name(type, index)`, `duckdb_struct_type_child_type(type, index)`, `duckdb_union_type_member_count(type)`, `duckdb_union_type_member_name(type, index)`, `duckdb_union_type_member_type(type, index)`, `duckdb_destroy_logical_type(*type)`, `duckdb_register_logical_type(con, type, info)`. Data Chunk: `duckdb_create_data_chunk(types, column_count)`, `duckdb_destroy_data_chunk(*chunk)`, `duckdb_data_chunk_reset(chunk)`, `duckdb_data_chunk_get_column_count(chunk)`, `duckdb_data_chunk_get_vector(chunk, col_idx)`, `duckdb_data_chunk_get_size(chunk)`, `duckdb_data_chunk_set_size(chunk, size)`. Vector: `duckdb_vector_get_column_type(vector)`, `duckdb_vector_get_data(vector)`, `duckdb_vector_get_validity(vector)`, `duckdb_vector_ensure_validity_writable(vector)`, `duckdb_vector_assign_string_element(vector, index, str)`, `duckdb_vector_assign_string_element_len(vector, index, str, str_len)`, `duckdb_list_vector_get_child(vector)`, `duckdb_list_vector_get_size(vector)`, `duckdb_list_vector_set_size(vector, size)`, `duckdb_list_vector_reserve(vector, required_capacity)`, `duckdb_struct_vector_get_child(vector, index)`, `duckdb_array_vector_get_child(vector)`. Validity Mask: `duckdb_validity_row_is_valid(validity, row)`, `duckdb_validity_set_row_validity(validity, row, valid)`, `duckdb_validity_set_row_invalid(validity, row)`, `duckdb_validity_set_row_valid(validity, row)`. Scalar: `duckdb_create_scalar_function()`, `duckdb_destroy_scalar_function(*scalar_function)`, `duckdb_scalar_function_set_name(scalar_function, name)`, `duckdb_scalar_function_set_varargs(scalar_function, type)`, `duckdb_scalar_function_set_special_handling(scalar_function)`, `duckdb_scalar_function_set_volatile(scalar_function)`, `duckdb_scalar_function_add_parameter(scalar_function, type)`, `duckdb_scalar_function_set_return_type(scalar_function, type)`, `duckdb_scalar_function_set_extra_info(scalar_function, extra_info, destroy)`, `duckdb_scalar_function_set_function(scalar_function, function)`, `duckdb_register_scalar_function(con, scalar_function)`, `duckdb_scalar_function_get_extra_info(info)`, `duckdb_scalar_function_set_error(info, error)`, `duckdb_create_scalar_function_set(name)`, `duckdb_destroy_scalar_function_set(*scalar_function_set)`, `duckdb_add_scalar_function_to_set(set, function)`, `duckdb_register_scalar_function_set(con, set)`. Aggregate: `duckdb_create_aggregate_function()`, `duckdb_destroy_aggregate_function(*aggregate_function)`, `duckdb_aggregate_function_set_name(aggregate_function, name)`, `duckdb_aggregate_function_add_parameter(aggregate_function, type)`, `duckdb_aggregate_function_set_return_type(aggregate_function, type)`, `duckdb_aggregate_function_set_functions(aggregate_function, state_size, state_init, update, combine, finalize)`, `duckdb_aggregate_function_set_destructor(aggregate_function, destroy)`, `duckdb_register_aggregate_function(con, aggregate_function)`, `duckdb_aggregate_function_set_special_handling(aggregate_function)`, `duckdb_aggregate_function_set_extra_info(aggregate_function, extra_info, destroy)`, `duckdb_aggregate_function_get_extra_info(info)`, `duckdb_aggregate_function_set_error(info, error)`, `duckdb_create_aggregate_function_set(name)`, `duckdb_destroy_aggregate_function_set(*aggregate_function_set)`, `duckdb_add_aggregate_function_to_set(set, function)`, `duckdb_register_aggregate_function_set(con, set)`. Table: `duckdb_create_table_function()`, `duckdb_destroy_table_function(*table_function)`, `duckdb_table_function_set_name(table_function, name)`, `duckdb_table_function_add_parameter(table_function, type)`, `duckdb_table_function_add_named_parameter(table_function, name, type)`, `duckdb_table_function_set_extra_info(table_function, extra_info, destroy)`, `duckdb_table_function_set_bind(table_function, bind)`, `duckdb_table_function_set_init(table_function, init)`, `duckdb_table_function_set_local_init(table_function, init)`, `duckdb_table_function_set_function(table_function, function)`, `duckdb_table_function_supports_projection_pushdown(table_function, pushdown)`, `duckdb_register_table_function(con, function)`. Table Bind: `duckdb_bind_get_extra_info(info)`, `duckdb_bind_add_result_column(info, name, type)`, `duckdb_bind_get_parameter_count(info)`, `duckdb_bind_get_parameter(info, index)`, `duckdb_bind_get_named_parameter(info, name)`, `duckdb_bind_set_bind_data(info, bind_data, destroy)`, `duckdb_bind_set_cardinality(info, cardinality, is_exact)`, `duckdb_bind_set_error(info, error)`. Table Init: `duckdb_init_get_extra_info(info)`, `duckdb_init_get_bind_data(info)`, `duckdb_init_set_init_data(info, init_data, destroy)`, `duckdb_init_get_column_count(info)`, `duckdb_init_get_column_index(info, column_index)`, `duckdb_init_set_max_threads(info, max_threads)`, `duckdb_init_set_error(info, error)`. Table Function: `duckdb_function_get_extra_info(info)`, `duckdb_function_get_bind_data(info)`, `duckdb_function_get_init_data(info)`, `duckdb_function_get_local_init_data(info)`, `duckdb_function_set_error(info, error)`. Replacement Scans: `duckdb_add_replacement_scan(db, replacement, extra_data, delete_callback)`, `duckdb_replacement_scan_set_function_name(info, function_name)`, `duckdb_replacement_scan_add_parameter(info, parameter)`, `duckdb_replacement_scan_set_error(info, error)`. Profiling: `duckdb_get_profiling_info(connection)`, `duckdb_profiling_info_get_value(info, key)`, `duckdb_profiling_info_get_metrics(info)`, `duckdb_profiling_info_get_child_count(info)`, `duckdb_profiling_info_get_child(info, index)`. Appender: `duckdb_appender_create(connection, schema, table, *out_appender)`, `duckdb_appender_column_count(appender)`, `duckdb_appender_column_type(appender, col_idx)`, `duckdb_appender_error(appender)`, `duckdb_appender_flush(appender)`, `duckdb_appender_close(appender)`, `duckdb_appender_destroy(*appender)`, `duckdb_appender_begin_row(appender)`, `duckdb_appender_end_row(appender)`, `duckdb_append_default(appender)`, `duckdb_append_bool(appender, value)`, `duckdb_append_int8(appender, value)`, `duckdb_append_int16(appender, value)`, `duckdb_append_int32(appender, value)`, `duckdb_append_int64(appender, value)`, `duckdb_append_hugeint(appender, value)`, `duckdb_append_uint8(appender, value)`, `duckdb_append_uint16(appender, value)`, `duckdb_append_uint32(appender, value)`, `duckdb_append_uint64(appender, value)`, `duckdb_append_uhugeint(appender, value)`, `duckdb_append_float(appender, value)`, `duckdb_append_double(appender, value)`, `duckdb_append_date(appender, value)`, `duckdb_append_time(appender, value)`, `duckdb_append_timestamp(appender, value)`, `duckdb_append_interval(appender, value)`, `duckdb_append_varchar(appender, val)`, `duckdb_append_varchar_length(appender, val, length)`, `duckdb_append_blob(appender, data, length)`, `duckdb_append_null(appender)`, `duckdb_append_data_chunk(appender, chunk)`. Table Description: `duckdb_table_description_create(connection, schema, table, *out)`, `duckdb_table_description_destroy(*table_description)`, `duckdb_table_description_error(table_description)`, `duckdb_column_has_default(table_description, index, *out)`. Arrow: `duckdb_query_arrow(connection, query, *out_result)`, `duckdb_query_arrow_schema(result, *out_schema)`, `duckdb_prepared_arrow_schema(prepared, *out_schema)`, `duckdb_result_arrow_array(result, chunk, *out_array)`, `duckdb_query_arrow_array(result, *out_array)`, `duckdb_arrow_column_count(result)`, `duckdb_arrow_row_count(result)`, `duckdb_arrow_rows_changed(result)`, `duckdb_query_arrow_error(result)`, `duckdb_destroy_arrow(*result)`, `duckdb_destroy_arrow_stream(*stream_p)`, `duckdb_execute_prepared_arrow(prepared_statement, *out_result)`, `duckdb_arrow_scan(connection, table_name, arrow)`, `duckdb_arrow_array_scan(connection, table_name, arrow_schema, arrow_array, *out_stream)`. Threading: `duckdb_execute_tasks(database, max_tasks)`, `duckdb_create_task_state(database)`, `duckdb_execute_tasks_state(state)`, `duckdb_execute_n_tasks_state(state, max_tasks)`, `duckdb_finish_execution(state)`, `duckdb_task_state_is_finished(state)`, `duckdb_destroy_task_state(state)`, `duckdb_execution_is_finished(con)`. Streaming: `duckdb_stream_fetch_chunk(result)`, `duckdb_fetch_chunk(result)`. Cast: `duckdb_create_cast_function()`, `duckdb_cast_function_set_source_type()`, `duckdb_cast_function_set_target_type()`, `duckdb_cast_function_set_implicit_cast_cost()`, `duckdb_cast_function_set_function()`, `duckdb_cast_function_set_extra_info()`, `duckdb_cast_function_get_extra_info()`, `duckdb_cast_function_get_cast_mode()`, `duckdb_cast_function_set_error()`, `duckdb_cast_function_set_row_error()`, `duckdb_register_cast_function()`, `duckdb_destroy_cast_function()`. Appender: Efficiently load data into DuckDB via C interface. duckdb_state duckdb_appender_create(duckdb_connection connection, const char *schema, const char *table, duckdb_appender *out_appender) Creates an appender. idx_t duckdb_appender_column_count(duckdb_appender appender) Returns column count. duckdb_logical_type duckdb_appender_column_type(duckdb_appender appender, idx_t col_idx) Returns column type. const char *duckdb_appender_error(duckdb_appender appender) Returns error message. duckdb_state duckdb_appender_flush(duckdb_appender appender) Flushes the appender. Returns DuckDBError on constraint violations. duckdb_state duckdb_appender_close(duckdb_appender appender) Closes the appender and flushes. Returns DuckDBError on constraint violations. duckdb_state duckdb_appender_destroy(duckdb_appender *appender) Destroys the appender. duckdb_state duckdb_appender_begin_row(duckdb_appender appender) Nop function for compatibility. duckdb_state duckdb_appender_end_row(duckdb_appender appender) Finishes current row. duckdb_state duckdb_append_default(duckdb_appender appender) Appends a DEFAULT value. duckdb_state duckdb_append_bool(duckdb_appender appender, bool value) Appends a bool value. duckdb_state duckdb_append_int8(duckdb_appender appender, int8_t value) Appends an int8 value. duckdb_state duckdb_append_int16(duckdb_appender appender, int16_t value) Appends an int16 value. duckdb_state duckdb_append_int32(duckdb_appender appender, int32_t value) Appends an int32 value. duckdb_state duckdb_append_int64(duckdb_appender appender, int64_t value) Appends an int64 value. duckdb_state duckdb_append_hugeint(duckdb_appender appender, duckdb_hugeint value) Appends a hugeint value. duckdb_state duckdb_append_uint8(duckdb_appender appender, uint8_t value) Appends a uint8 value. duckdb_state duckdb_append_uint16(duckdb_appender appender, uint16_t value) Appends a uint16 value. duckdb_state duckdb_append_uint32(duckdb_appender appender, uint32_t value) Appends a uint32 value. duckdb_state duckdb_append_uint64(duckdb_appender appender, uint64_t value) Appends a uint64 value. duckdb_state duckdb_append_uhugeint(duckdb_appender appender, duckdb_uhugeint value) Appends an uhugeint value. duckdb_state duckdb_append_float(duckdb_appender appender, float value) Appends a float value. duckdb_state duckdb_append_double(duckdb_appender appender, double value) Appends a double value. duckdb_state duckdb_append_date(duckdb_appender appender, duckdb_date value) Appends a date value. duckdb_state duckdb_append_time(duckdb_appender appender, duckdb_time value) Appends a time value. duckdb_state duckdb_append_timestamp(duckdb_appender appender, duckdb_timestamp value) Appends a timestamp value. duckdb_state duckdb_append_interval(duckdb_appender appender, duckdb_interval value) Appends an interval value. duckdb_state duckdb_append_varchar(duckdb_appender appender, const char *val) Appends a varchar value. duckdb_state duckdb_append_varchar_length(duckdb_appender appender, const char *val, idx_t length) Appends varchar with length. duckdb_state duckdb_append_blob(duckdb_appender appender, const void *data, idx_t length) Appends a blob. duckdb_state duckdb_append_null(duckdb_appender appender) Appends NULL. duckdb_state duckdb_append_data_chunk(duckdb_appender appender, duckdb_data_chunk chunk) Appends a data chunk. Configuration options for DuckDB. duckdb_state duckdb_create_config(duckdb_config *out_config) Creates a configuration object. size_t duckdb_config_count() Returns the config option count. duckdb_state duckdb_get_config_flag(size_t index, const char **out_name, const char **out_description) Gets config option details by index. duckdb_state duckdb_set_config(duckdb_config config, const char *name, const char *option) Sets a config option. void duckdb_destroy_config(duckdb_config *config) Destroys a configuration object. C API Startup & Shutdown. duckdb_open(path, out_database) opens/creates database (path NULL for in-memory). duckdb_open_ext(path, out_database, config, out_error) extended open. duckdb_close(database) closes database. duckdb_connect(database, out_connection) connects to database. duckdb_disconnect(connection) disconnects. duckdb_interrupt(connection) interrupts query. duckdb_query_progress(connection) gets query progress. duckdb_library_version() gets version. Use duckdb_close & duckdb_disconnect to avoid leaks. Thread-safe connections, connection per thread recommended. Data Chunks: Horizontal slice of a table, holding vectors with up to VECTOR_SIZE rows. Used for reading and writing data. duckdb_create_data_chunk(duckdb_logical_type *types, idx_t column_count): Creates an empty data chunk. Returns duckdb_data_chunk. duckdb_destroy_data_chunk(duckdb_data_chunk *chunk): Destroys a data chunk. duckdb_data_chunk_reset(duckdb_data_chunk chunk): Resets a data chunk. duckdb_data_chunk_get_column_count(duckdb_data_chunk chunk): Returns number of columns (idx_t). duckdb_data_chunk_get_vector(duckdb_data_chunk chunk, idx_t col_idx): Returns vector at column index (duckdb_vector). duckdb_data_chunk_get_size(duckdb_data_chunk chunk): Returns number of tuples (idx_t). duckdb_data_chunk_set_size(duckdb_data_chunk chunk, idx_t size): Sets the number of tuples. Command Line Arguments: -append: Append database to file. -ascii: Set output mode to ascii. -bail: Stop after error. -batch: Force batch I/O. -box: Set output mode to box. -column: Set output mode to column. -cmd COMMAND: Run COMMAND before stdin. -c COMMAND: Run COMMAND and exit. -csv: Set output mode to csv. -echo: Print commands before execution. -init FILENAME: Run script on startup. -header: Turn headers on. -help: Show this message. -html: Set output mode to HTML. -interactive: Force interactive I/O. -json: Set output mode to json. -line: Set output mode to line. -list: Set output mode to list. -markdown: Set output mode to markdown. -newline SEP: Set row separator. -nofollow: Refuse symbolic links. -noheader: Turn headers off. -no-stdin: Exit after options. -nullvalue TEXT: Set NULL string. -quote: Set output mode to quote. -readonly: Open read-only. -s COMMAND: Run COMMAND and exit. -separator SEP: Set column separator. -stats: Print memory stats. -table: Set output mode to table. -unsigned: Allow unsigned extensions. -version: Show version. Shell autocomplete: triggered by Tab. Cycle suggestions: Tab/Shift+Tab. Revert: ESC twice. Autocomplete groups: Keywords, Table names, Column names, File names. Context-aware based on SQL position. Dot Commands: .help ?-all? ?PATTERN? - Show help. .bail on|off - Stop on error. .binary on|off - Binary output. .cd DIRECTORY - Change directory. .changes on|off - Show rows changed. .check GLOB - Fail if output doesn't match. .columns - Column-wise output. .constant ?COLOR? - Set constant color. .constantcode ?CODE? - Set constant terminal code. .databases - List databases. .echo on|off - Echo commands. .excel - Spreadsheet output. .exit ?CODE? - Exit program. .explain ?on|off|auto? - Explain formatting. .fullschema ?--indent? - Show schema. .headers on|off - Show headers. .highlight [on|off] - Toggle syntax highlighting. .import FILE TABLE - Import data. Deprecated. .indexes ?TABLE? - Show indexes. .keyword ?COLOR? - Set keyword color. .keywordcode ?CODE? - Set keyword terminal code. .lint OPTIONS - Report schema issues. .log FILE|off - Turn logging on/off. .maxrows COUNT - Max rows for display. .maxwidth COUNT - Max width. .mode MODE ?TABLE? - Set output mode. .multiline - Multi-line mode. .nullvalue STRING - Use string for NULL. .once ?OPTIONS? ?FILE? - Output next command to file. .open ?OPTIONS? ?FILE? - Open database file. .output ?FILE? - Send output to file. .parameter CMD ... - Manage SQL parameters. .print STRING... - Print string. .prompt MAIN CONTINUE - Replace prompts. .quit - Exit program. .read FILE - Read input from file. .rows - Row-wise output. .schema ?PATTERN? - Show CREATE statements. .separator COL ?ROW? - Change separators. .sha3sum ... - Compute SHA3 hash. .shell CMD ARGS... - Run shell command. .show - Show settings. .singleline - Single-line mode. .system CMD ARGS... - Run system command. .tables ?TABLE? - List tables. .testcase NAME - Redirect output. .timer on|off - SQL timer. .width NUM1 NUM2 ... - Set column widths. Example: .mode markdown. .output my_results.md SELECT 'taking flight' AS output_column;.output CLI Editing (macOS/Linux): linenoise-based editor (Emacs-like shortcuts). Keybindings: Moving (Left, Right, Up, Down, Home, End, Ctrl+Left/Right/A/B/E/F, Alt+Left/Right), History (Ctrl+P/N/R/S, Alt+/N/P), Changing Text (Backspace, Delete, Ctrl+D/H/K/T/U/W, Alt+C/D/L/R/T/U/Backspace/\\), Completing (Tab, Shift+Tab, Esc+Esc), Miscellaneous (Enter/Ctrl+J - execute, Ctrl+C/G/O - cancel, Ctrl+L - clear, Ctrl+X - newline, Ctrl+Z - suspend). rlwrap for readline support. .mode command changes terminal output format. Supported modes: ascii, box, csv, column, duckbox, html, insert, json, jsonlines, latex, line, list, markdown, quote, table, tabs, tcl, trash. .separator command customizes separators. DuckDB CLI: Command Line Interface. Usage: duckdb [OPTIONS] [FILENAME]. Options: -csv -json -readonly. Dot commands: start with '.'. .help: commands list. .open [FILENAME] [--readonly]: open database. .mode [MODE]: output format. .output [FILENAME]: output to file. .read [FILENAME]: run SQL from file. Exit: Ctrl+D Ctrl+C .exit. Config: ~/.duckdbrc. Non-interactive: duckdb < script.sql. Extensions: INSTALL LOAD. stdin/stdout: /dev/stdin /dev/stdout. getenv(var): env variables. PREPARE EXECUTE: prepared statements. CLI syntax highlighting (macOS/Linux). Configurable components: .keyword, .constant, .comment, .error, .cont, .cont_sel. Configurable colors: .keyword red, etc. Disable highlighting: .highlight off. Error highlighting: mismatched brackets, unclosed quotes (red). Disable error highlighting: .render_errors off. Config file: ~/.duckdbrc. DuckDB C API duckdb.h. SQLite API wrapper. Install libduckdb package. Startup Shutdown Full API overview sections. C++ API: Internal, unstable. Use C API for applications. DuckDB: Database instance. Constructor: DuckDB(path, DBConfig*). nullptr for in-memory. Connection: Connection to database. Constructor: Connection(DuckDB&). Thread-safe, but locking during queries. QueryResult: Result of queries. Query(): Executes SQL query. Returns MaterializedQueryResult. Prepare(): Prepares a statement. Returns PreparedStatement. Execute(params). Avoid for large data imports. CreateScalarFunction(name, udf_func): Creates scalar UDF. CreateScalarFunction(name, args, ret_type, udf_func): Creates scalar UDF with specified types. CreateVectorizedFunction(name, udf_func, varargs): Creates vectorized UDF. CreateVectorizedFunction(name, args, ret_type, udf_func, varargs) Prepared Statements (C API): Parameterized queries using ? or $1. duckdb_prepare(con, query, &stmt): create prepared statement. MUST destroy with duckdb_destroy_prepare. duckdb_bind_TYPE(stmt, param_index, value): bind parameter (index from 1). duckdb_execute_prepared(stmt, &result): execute, result=NULL if no result set. duckdb_destroy_prepare(&stmt): destroy statement. duckdb_prepare_error(stmt): get error. duckdb_nparams(stmt): num params. duckdb_param_type(stmt, param_idx): param type. duckdb_clear_bindings(stmt): clear bindings. duckdb_prepared_statement_type(stmt): statement type. Warning: Avoid for large inserts, use Appender. duckdb_query(connection, query, out_result) state: Executes SQL query. duckdb_destroy_result(result): Deallocates result memory. duckdb_column_name(result, col) const char*: Returns column name. duckdb_column_type(result, col) type: Returns column type. duckdb_result_statement_type(result) statement_type: Returns statement type. duckdb_column_logical_type(result, col) logical_type: Returns logical column type. duckdb_column_count(result) idx_t: Returns column count. duckdb_row_count(result) idx_t: Returns row count. Deprecated. duckdb_rows_changed(result) idx_t: Returns changed rows. duckdb_column_data(result, col) void*: Returns column data. Deprecated. duckdb_nullmask_data(result, col) bool*: Returns nullmask. Deprecated. duckdb_result_error(result) const char*: Returns error message. duckdb_result_error_type(result) error_type: Returns error type. Replacement Scans: Register callback for non-existent tables, replace table read with function. API: `duckdb_add_replacement_scan(db, replacement, extra_data, delete_callback)`: add replacement scan. `duckdb_replacement_scan_set_function_name(info, function_name)`: set function name. `duckdb_replacement_scan_add_parameter(info, parameter)`: add parameter. `duckdb_replacement_scan_set_error(info, error)`: set error. Table Functions: API to define table functions. duckdb_create_table_function(): Creates a new empty table function; returns duckdb_table_function. duckdb_destroy_table_function(duckdb_table_function *table_function): Destroys table_function. duckdb_table_function_set_name(duckdb_table_function table_function, const char *name): Sets table_function name. duckdb_table_function_add_parameter(duckdb_table_function table_function, duckdb_logical_type type): Adds a parameter of type to table_function. duckdb_table_function_add_named_parameter(duckdb_table_function table_function, const char *name, duckdb_logical_type type): Adds a named parameter to table_function. duckdb_table_function_set_extra_info(duckdb_table_function table_function, void *extra_info, duckdb_delete_callback_t destroy): Sets extra_info for table_function, called during binding. duckdb_table_function_set_bind(duckdb_table_function table_function, duckdb_table_function_bind_t bind): Sets bind function. duckdb_table_function_set_init(duckdb_table_function table_function, duckdb_table_function_init_t init): Sets init function. duckdb_table_function_set_local_init(duckdb_table_function table_function, duckdb_table_function_init_t init): Sets thread-local init function. duckdb_table_function_set_function(duckdb_table_function table_function, duckdb_table_function_t function): Sets main function. duckdb_table_function_supports_projection_pushdown(duckdb_table_function table_function, bool pushdown): Sets projection pushdown support. duckdb_register_table_function(duckdb_connection con, duckdb_table_function function): Registers table_function in con; returns duckdb_state. duckdb_bind_get_extra_info(duckdb_bind_info info): Retrieves extra_info. duckdb_bind_add_result_column(duckdb_bind_info info, const char *name, duckdb_logical_type type): Adds result column. duckdb_bind_get_parameter_count(duckdb_bind_info info): Retrieves parameter count. duckdb_bind_get_parameter(duckdb_bind_info info, idx_t index): Retrieves parameter at index; returns duckdb_value. duckdb_bind_get_named_parameter(duckdb_bind_info info, const char *name): Retrieves named parameter; returns duckdb_value. duckdb_bind_set_bind_data(duckdb_bind_info info, void *bind_data, duckdb_delete_callback_t destroy): Sets bind_data. duckdb_bind_set_cardinality(duckdb_bind_info info, idx_t cardinality, bool is_exact): Sets cardinality estimate. duckdb_bind_set_error(duckdb_bind_info info, const char *error): Reports bind error. duckdb_init_get_extra_info(duckdb_init_info info): Retrieves extra_info. duckdb_init_get_bind_data(duckdb_init_info info): Gets bind_data. duckdb_init_set_init_data(duckdb_init_info info, void *init_data, duckdb_delete_callback_t destroy): Sets init_data. duckdb_init_get_column_count(duckdb_init_info info): Returns number of projected columns (if pushdown enabled). duckdb_init_get_column_index(duckdb_init_info info, idx_t column_index): Returns column index of projected column at column_index (if pushdown enabled). duckdb_init_set_max_threads(duckdb_init_info info, idx_t max_threads): Sets max threads. duckdb_init_set_error(duckdb_init_info info, const char *error): Report init error. duckdb_function_get_extra_info(duckdb_function_info info): Retrieves extra_info. duckdb_function_get_bind_data(duckdb_function_info info): Gets bind_data. duckdb_function_get_init_data(duckdb_function_info info): Gets init_data. duckdb_function_get_local_init_data(duckdb_function_info info): Gets thread-local init_data. duckdb_function_set_error(duckdb_function_info info, const char *error): Report function error. duckdb_type: enum for primitive types. duckdb_logical_type: class for complex types. duckdb_column_type(result): gets enum type. duckdb_column_logical_type(result): gets logical type. duckdb_value_*(column): fetches value (auto-casts). duckdb_value_is_null(column): checks for NULL. duckdb_fetch_chunk(result, chunk_index): reads data chunks. duckdb_result_get_chunk(result, chunk_index): Returns a data chunk. duckdb_result_is_streaming(result): Checks if result is streaming. duckdb_result_chunk_count(result): Returns number of chunks. duckdb_result_return_type(result): Returns the return type. duckdb_from_date(date): decompose date. duckdb_to_date(date_struct): compose date. duckdb_is_finite_date(date): check if date is finite. duckdb_from_time(time): decompose time. duckdb_create_time_tz(micros, offset): creates time_tz. duckdb_from_time_tz(time_tz): decompose time_tz. duckdb_to_time(time_struct): compose time. duckdb_from_timestamp(ts): decompose timestamp. duckdb_to_timestamp(ts_struct): compose timestamp. duckdb_is_finite_timestamp(ts): check if timestamp is finite. duckdb_hugeint_to_double(val): hugeint to double. duckdb_double_to_hugeint(val): double to hugeint. duckdb_double_to_decimal(val, width, scale): double to decimal. duckdb_decimal_to_double(val): decimal to double. duckdb_create_logical_type(type): create logical type. duckdb_logical_type_get_alias(type): get alias. duckdb_logical_type_set_alias(type, alias): set alias. duckdb_create_list_type(type): create list type. duckdb_create_array_type(type, size): create array type. duckdb_create_map_type(key_type, value_type): create map type. duckdb_create_union_type(member_types, member_names, count): create union type. duckdb_create_struct_type(member_types, member_names, count): create struct type. duckdb_create_enum_type(member_names, count): create enum type. duckdb_create_decimal_type(width, scale): create decimal type. duckdb_get_type_id(type): get type id. duckdb_decimal_width(type): get decimal width. duckdb_decimal_scale(type): get decimal scale. duckdb_decimal_internal_type(type): get decimal internal type. duckdb_enum_internal_type(type): get enum internal type. duckdb_enum_dictionary_size(type): get enum dictionary size. duckdb_enum_dictionary_value(type, index): get enum dictionary value. duckdb_list_type_child_type(type): get list child type. duckdb_array_type_child_type(type): get array child type. duckdb_array_type_array_size(type): get array size. duckdb_map_type_key_type(type): get map key type. duckdb_map_type_value_type(type): get map value type. duckdb_struct_type_child_count(type): get struct child count. duckdb_struct_type_child_name(type, index): get struct child name. duckdb_struct_type_child_type(type, index): get struct child type. duckdb_union_type_member_count(type): get union member count. duckdb_union_type_member_name(type, index): get union member name. duckdb_union_type_member_type(type, index): get union member type. duckdb_destroy_logical_type(type): destroy logical type. duckdb_register_logical_type(con, type, info): register logical type. Values: Represents a single value of any type. duckdb_destroy_value(duckdb_value *value): Destroys the value. duckdb_create_varchar(const char *text): Creates from null-terminated string. Returns duckdb_value. duckdb_create_varchar_length(const char *text, idx_t length): Creates from string with length. Returns duckdb_value. duckdb_create_bool(bool input): Creates from bool. Returns duckdb_value. duckdb_create_int8(int8_t input): Creates from int8_t. Returns duckdb_value. duckdb_create_uint8(uint8_t input): Creates from uint8_t. Returns duckdb_value. duckdb_create_int16(int16_t input): Creates from int16_t. Returns duckdb_value. duckdb_create_uint16(uint16_t input): Creates from uint16_t. Returns duckdb_value. duckdb_create_int32(int32_t input): Creates from int32_t. Returns duckdb_value. duckdb_create_uint32(uint32_t input): Creates from uint32_t. Returns duckdb_value. duckdb_create_int64(int64_t val): Creates from int64_t. Returns duckdb_value. duckdb_create_uint64(uint64_t input): Creates from uint64_t. Returns duckdb_value. duckdb_create_hugeint(duckdb_hugeint input): Creates from hugeint. Returns duckdb_value. duckdb_create_uhugeint(duckdb_uhugeint input): Creates from uhugeint. Returns duckdb_value. duckdb_create_float(float input): Creates from float. Returns duckdb_value. duckdb_create_double(double input): Creates from double. Returns duckdb_value. duckdb_create_date(duckdb_date input): Creates from date. Returns duckdb_value. duckdb_create_time(duckdb_time input): Creates from time. Returns duckdb_value. duckdb_create_time_tz_value(duckdb_time_tz value): Creates from time_tz. Returns duckdb_value. duckdb_create_timestamp(duckdb_timestamp input): Creates from timestamp. Returns duckdb_value. duckdb_create_interval(duckdb_interval input): Creates from interval. Returns duckdb_value. duckdb_create_blob(const uint8_t *data, idx_t length): Creates from blob. Returns duckdb_value. duckdb_get_bool(duckdb_value val): Returns bool. duckdb_get_int8(duckdb_value val): Returns int8_t. duckdb_get_uint8(duckdb_value val): Returns uint8_t. duckdb_get_int16(duckdb_value val): Returns int16_t. duckdb_get_uint16(duckdb_value val): Returns uint16_t. duckdb_get_int32(duckdb_value val): Returns int32_t. duckdb_get_uint32(duckdb_value val): Returns uint32_t. duckdb_get_int64(duckdb_value val): Returns int64_t. duckdb_get_uint64(duckdb_value val): Returns uint64_t. duckdb_get_hugeint(duckdb_value val): Returns duckdb_hugeint. duckdb_get_uhugeint(duckdb_value val): Returns duckdb_uhugeint. duckdb_get_float(duckdb_value val): Returns float. duckdb_get_double(duckdb_value val): Returns double. duckdb_get_date(duckdb_value val): Returns duckdb_date. duckdb_get_time(duckdb_value val): Returns duckdb_time. duckdb_get_time_tz(duckdb_value val): Returns duckdb_time_tz. duckdb_get_timestamp(duckdb_value val): Returns duckdb_timestamp. duckdb_get_interval(duckdb_value val): Returns duckdb_interval. duckdb_get_value_type(duckdb_value val): Returns duckdb_logical_type. duckdb_get_blob(duckdb_value val): Returns duckdb_blob. duckdb_get_varchar(duckdb_value value): Returns char*. Must be freed with duckdb_free. duckdb_create_struct_value(duckdb_logical_type type, duckdb_value *values): Creates struct value. Returns duckdb_value. duckdb_create_list_value(duckdb_logical_type type, duckdb_value *values, idx_t value_count): Creates list value. Returns duckdb_value. duckdb_create_array_value(duckdb_logical_type type, duckdb_value *values, idx_t value_count): Creates array value. Returns duckdb_value. duckdb_get_map_size(duckdb_value value): Returns number of elements in a MAP value. duckdb_get_map_key(duckdb_value value, idx_t index): Returns MAP key at index as duckdb_value. duckdb_get_map_value(duckdb_value value, idx_t index): Returns MAP value at index as duckdb_value. Vectors: horizontal slice of a column. duckdb_vector_get_column_type(vector). duckdb_vector_get_data(vector). duckdb_vector_get_validity(vector). duckdb_vector_ensure_validity_writable(vector). duckdb_vector_assign_string_element(vector, index, str). duckdb_vector_assign_string_element_len(vector, index, str, str_len). duckdb_list_vector_get_child(vector). duckdb_list_vector_get_size(vector). duckdb_list_vector_set_size(vector, size). duckdb_list_vector_reserve(vector, required_capacity). duckdb_struct_vector_get_child(vector, index). duckdb_array_vector_get_child(vector). duckdb_validity_row_is_valid(validity, row). duckdb_validity_set_row_validity(validity, row, valid). duckdb_validity_set_row_invalid(validity, row). duckdb_validity_set_row_valid(validity, row). Dart API DuckDB.Dart. Install: flutter pub add dart_duckdb. Import: import 'package:dart_duckdb/dart_duckdb.dart';. Usage: duckdb.open(":memory:"), duckdb.connect(db), connection.execute(sql), connection.query(sql).fetchAll(), Isolate.spawn(backgroundTask, db.transferrable), duckdb.connectWithTransferred(transferableDb). Example: final db = duckdb.open(":memory:"); final connection = duckdb.connect(db); connection.execute('CREATE TABLE ...'); connection.query('SELECT ...').fetchAll(); connection.dispose(); db.dispose(); Go API database/sql duckdb.NewConnector(dbpath config) connector connector.Connect(context) connection NewAppenderFromConn(conn schema table) appender bulk insert appender.AppendRow(...) append data appender.Flush() flush data Java JDBC API for DuckDB DriverManager.getConnection(jdbcUrl) creates connection jdbc:duckdb: in-memory jdbc:duckdb:/path/to/db persistent DuckDBConnection for duckdb features DuckDBConnection.duplicate() copy connection Statement.execute(sql) sql no result Statement.executeQuery(sql) sql ResultSet PreparedStatement prepared statements avoid bulk insert Arrow DuckDBResultSet.arrowExportStream() DuckDBConnection.registerArrowStream() Streaming results JDBC_STREAM_RESULTS property DuckDBAppender bulk insert DuckDBConnection.createAppender(schema table) append() close() Batch writer PreparedStatement/Statement addBatch() executeBatch() Error ClassNotFoundException dependency issue Julia Package. DBInterface frontend. Multi-threaded. DBInterface.connect(DuckDB.DB, ":memory:") connect. DBInterface.execute(con, sql) execute SQL. DBInterface.prepare(con, sql) prepare. DBInterface.execute(stmt, params) execute prepared. DuckDB.query(sql) query SQL. DuckDB.register_data_frame(con, df, name) register DataFrame. DuckDB.Appender(db, table) appender. DuckDB.append(appender, value) append value. DuckDB.end_row(appender) end row. DuckDB.close(appender) close appender. Concurrent read/write with separate connections. Classes: Database, Connection, Statement. Methods (Database): new duckdb.Database(filename: str, options, callback), db.all(sql: str, ...), db.each(sql: str, ...), db.run(sql: str, ...), db.exec(sql: str), db.connect(), db.register_buffer(name: str, buffers, persist: bool, callback). Methods (Connection): con.all(sql: str, ...), con.each(sql: str, ...), con.run(sql: str, ...), con.prepare(sql: str, callback). Methods (Statement): stmt.all(...), stmt.run(...), stmt.finalize(). Node.js API (Neo) for DuckDB. Depends on @duckdb/duckdb-bindings. DuckDBInstance.create(db_path, config): Creates a DuckDB instance. db_path=":memory:" for in-memory. config: {threads: string} instance.connect(): Creates a connection. connection.run(sql): Runs SQL. Returns result. connection.prepare(sql): Prepares SQL statement. prepared.bindVarchar(index, value), bindInteger(index, value): Binds parameters. prepared.run(): Executes prepared statement. Returns result. result.columnNames(): Returns column names. result.columnTypes(): Returns column types. result.fetchAllChunks(): Fetches all chunks. result.fetchChunk(): Fetches one chunk. chunk.getColumns(): Column-major data. chunk.getRows(): Row-major data. chunk.getColumnVector(columnIndex).getItem(itemIndex): Get a single value. connection.runAndReadAll(sql): Runs SQL and reads all data. connection.runAndReadUtil(sql, rows): Runs SQL and reads up to rows. reader.getRows(): Get rows. reader.getColumns(): Get columns. reader.readUntil(rows): Reads rows incrementally. DuckDBTypeId: ENUM, ARRAY, DECIMAL, LIST, MAP, STRUCT, UNION columnType properties: typeId, valueType, length, width, scale, values, keyType, names, memberTags, memberTypes columnValue properties: items, bytes, days, months, micros, seconds, nanoseconds, tag, value, hugeint columnValue methods: toBools(), toBits(), toParts(), toDouble() connection.createAppender(schema, table): Creates appender. appender.appendInteger(value), appendVarchar(value): Appends data. appender.endRow(): Ends row. appender.flush(): Flushes data. appender.close(): Closes appender. connection.extractStatements(sql): Extracts statements. extractedStatements.prepare(stmtIndex): Prepares a statement. prepared.parameterCount: Number of parameters. pending = prepared.start(): Starts asynchronous execution. pending.runTask(): Executes a task. Returns DuckDBPendingResultState. pending.getResult(): Gets the result. DuckDBPendingResultState: RESULT_READY ODBC Configuration files: odbc.ini, odbcinst.ini. odbc.ini: DSNs, [DSN_NAME], Driver=driver_name, Database=db_path, access_mode, allow_unsigned_extensions. odbcinst.ini: Driver config, [ODBC] Trace=yes/no, TraceFile=path, [Driver_Name Driver] Driver=driver_path. ODBC API on Linux: Requires Driver Manager (unixODBC). Install: Debian: sudo apt-get install unixodbc odbcinst, Fedora: sudo yum install unixODBC. Setup: Download ODBC Linux Asset (x86_64, arm64). Contains: libduckdb_odbc.so, unixodbc_setup.sh. Usage: ./unixodbc_setup.sh [-u (user) | -s (system)] [-db database_path] [-D driver_path]. Config files: ~/.odbc.ini, /etc/odbc.ini, ~/.odbcinst.ini, /etc/odbcinst.ini. ODBC API macOS. Requires unixODBC (brew install unixodbc). Download driver. Configure via odbc.ini or SQLDriverConnect. Use isql client to validate. Supports DuckDB config options. ODBC API: C-style API for database access. Uses Driver Manager (DM) and ODBC drivers. DuckDB supports ODBC version 3.0. ODBC API on Windows: Requires ODBC Driver Manager (odbccp32.dll). Download and install DuckDB ODBC driver. Configure DSN using odbc_install.exe or odbcad32.exe. DSN configuration in ODBC.INI and ODBCINST.INI. Update driver by overwriting existing one. Registry keys: HKLM\SOFTWARE\ODBC\ODBC.INI, HKLM\SOFTWARE\ODBC\ODBCINST.INI. Client APIs Overview: DuckDB APIs for various languages. APIs: CLI, ADBC API, C, C#, C++, Common Lisp, Crystal, Dart, Elixir, Erlang, Go, Java, Julia, Node.js, ODBC API, Python, R, Ruby, Rust, Swift, WebAssembly (Wasm), Zig. Python to DuckDB type conversion: None->NULL, bool->BOOLEAN, timedelta->INTERVAL, str->VARCHAR, bytearray/memoryview->BLOB, Decimal->DECIMAL/DOUBLE, UUID->UUID, int->BIGINT/INTEGER/UBIGINT/UINTEGER/DOUBLE, float->DOUBLE/FLOAT, datetime->TIMESTAMP/TIMESTAMPTZ, time->TIME/TIMETZ, date->DATE, bytes->BLOB/BITSTRING, list->LIST, dict->STRUCT/MAP, tuple->LIST/STRUCT, numpy.ndarray/datetime64->LIST. DuckDB result to Python: NumPy fetchnumpy()->dict of NumPy arrays, Pandas df()/fetchdf()/fetch_df()->Pandas DataFrame, Arrow arrow()/fetch_arrow_table()->Arrow table, fetch_record_batch(chunk_size)->Arrow record batch reader, Polars pl()->Polars DataFrame. Python Data Ingestion. import duckdb. duckdb.read_csv(file, **options) reads CSV. duckdb.read_parquet(file, **options) reads Parquet. duckdb.read_json(file, **options) reads JSON. duckdb.sql(query) executes SQL. duckdb.register(name, obj) registers Python object as virtual table. Reads CSV/Parquet/JSON from file, folder, URL. Supports Pandas, Polars, Arrow in SQL. Pandas object columns may need pandas_analyze_sample config. DuckDBPyConnection: connect(database=":memory:", config=None, read_only=False), execute(sql, parameters=None), executemany(sql, parameters), fetchone(), fetchall(), close(). Supports prepared statements with ? or $n parameters, named parameters (dict). Exceptions: don't use executemany for large inserts. `con.execute("CREATE TABLE tbl AS SELECT 42 a")` `con.sql("SELECT * FROM tbl")` `con.execute("INSERT INTO items VALUES (?, ?, ?)", ["laptop", 2000, 1])` Classes: ColumnExpression, StarExpression, ConstantExpression, CaseExpression, FunctionExpression. Methods: .alias(name: str), .cast(type: DuckDBPyType), .isin(*exprs: Expression), .isnotin(*exprs: Expression), .isnotnull(), .isnull(), .asc(), .desc(), .nulls_first(), .nulls_last(). Python UDFs: Create and manage user-defined functions in DuckDB. create_function(name, function, parameters, return_type, type=None, null_handling=None, exception_handling=None, side_effects=False) Creates a UDF. Parameters: name, function, parameters (list of input types), return_type. remove_function(name) Removes a UDF. Type annotation can infer parameter and return types. null_handling: 'special' to handle NULLs in the function. exception_handling: 'return_null' to return NULL on exception. side_effects: True if the function has side effects. Function types: native (default), arrow (for arrow array input/output). Known Python Issues: Numpy import in multithreading, DESCRIBE/SUMMARIZE return empty tables (wrap in subquery), Protobuf error in JupySQL (fix protobuf package), EXPLAIN output contains newlines (print output), DLL load failed on Windows (install Microsoft Visual C++ Redistributable). Python API: Install with pip or conda. Requires Python 3.7+. duckdb.sql(query). Returns Relation. Data input: read_csv, read_parquet, read_json, read from file paths. Pandas, Polars, and Arrow DataFrame support (read-only). Result conversion: fetchall, df, pl, arrow, fetchnumpy. write_parquet, write_csv, COPY. duckdb.connect(dbname, config). Config: threads. Use DuckDBPyConnection.cursor() for multithreaded writes. install_extension, load_extension. Community extensions via repository="community". allow_unsigned_extensions in config. Python Relational API: DuckDBPyRelation for query build. duckdb.sql(sql), read_csv, read_parquet, from_arrow, from_df, read_json. Operations: aggregate(expr, groups), except_(rel), filter(condition), intersect(rel), join(rel, cond, type), limit(n, offset), order(expr), project(expr), union(rel). Output: write_csv, write_parquet. Spark API. from duckdb.experimental.spark.sql import SparkSession as session. spark.createDataFrame(pandas_df).withColumn( 'location', lit('Seattle') ).collect() Experimental. DuckDBPyType: Represents DuckDB data types. Implicit conversions from Python built-in types (bool->BOOLEAN, bytearray/bytes->BLOB, float->DOUBLE, int->BIGINT, str->VARCHAR), Numpy DTypes (bool->BOOLEAN, float32->FLOAT, float64->DOUBLE, int16->SMALLINT, int32->INTEGER, int64->BIGINT, int8->TINYINT, uint16->USMALLINT, uint32->UINTEGER, uint64->UBIGINT, uint8->UTINYINT). Nested types: list[child]->LIST, dict[key,value]->MAP, dict->STRUCT, Union->UNION. Creation functions: list_type(child_type), struct_type(fields), map_type(key_type, value_type), decimal_type(width, scale), union_type(members), string_type(collation). R API: Install: install.packages("duckdb"). dplyr API: install.packages("duckplyr"). DBI Interface. Startup/Shutdown: dbConnect(duckdb(), dbdir=":memory:", read_only=FALSE) - connection; :memory: in-memory db; dbDisconnect(con, shutdown=TRUE) - close. Querying: dbExecute(con, sql) - no result queries; dbGetQuery(con, sql) - result queries. Prepared statements: dbSendStatement(con, sql), dbBind(stmt, params), dbClearResult(stmt). Efficient Transfer: dbWriteTable(con, table_name, data.frame) - write df to table; duckdb_register(con, view_name, data.frame) - register df as view. dbplyr: dplyr integration (tbl). Memory Limit: SET memory_limit='2GB';. macOS install warning. Rust API. Install from crates.io. Connection::open(path: str) opens database file. Connection::open_in_memory() creates in-memory database (not persisted). conn.close() closes connection. conn.execute(sql: str, params) executes SQL. conn.prepare(sql: str) prepares statement. stmt.query_map(params, row_mapper) queries statement. conn.appender(table: str) creates appender. app.append_rows(rows) bulk inserts rows. Connections auto-closed on Drop. Swift API. Database instantiation: Database(store: .inMemory), Database(store: .file(at: "test.db")). Connection: database.connect(). Class ExoplanetStore { database: Database, connection: Connection, groupedByDiscoveryYear() async throws -> DataFrame }. Example: let database = try Database(store: .inMemory); let connection = try database.connect(); class ExoplanetStore { init(database: Database, connection: Connection) {}; static func create() async throws -> ExoplanetStore {}; func groupedByDiscoveryYear() async throws -> DataFrame {}}. Result casting: result[0].cast(to: Int.self). Data Ingestion (DuckDB-Wasm): 1. Register data file (registerEmptyFileBuffer, registerFileBuffer, registerFileHandle, registerFileText, registerFileURL). 2. Insert data (insertArrowFromIPCStream, insertArrowTable, insertCSVFromPath, insertJSONFromPath) or FROM SQL. Open/Close Connection: const c = await db.connect(); //connect await c.close(); //close Apache Arrow: insertArrowTable(table, {name}): Insert arrow.Table. insertArrowFromIPCStream(stream, {name}): Insert Arrow IPC stream. CSV: registerFileText(path, content): Register CSV content. insertCSVFromPath(path, {schema, name, detect, header, delimiter, columns}): Insert CSV from path. JSON: registerFileText(path, content): Register JSON content. insertJSONFromPath(path, {name}): Insert JSON. Supports row-major and column-major formats. Parquet: registerFileHandle(path, file, protocol, is_local): Register local Parquet file. registerFileURL(path, url, protocol, is_local): Register remote Parquet file. Use SQL: CREATE TABLE AS SELECT * FROM 'url.parquet'. const res = await fetch(url); await db.registerFileBuffer('buffer.parquet', new Uint8Array(await res.arrayBuffer())); httpfs (Wasm-flavored): Use SQL: CREATE TABLE AS SELECT * FROM 'url.parquet'. Insert Statement: c.query(`INSERT INTO table VALUES (1, 'foo')`); CORS: Configure S3 CORS for Network Error. DuckDB-Wasm extensions are Wasm files dynamically loaded. INSTALL is a no-op. LOAD fetches, checks signature, and dynamically loads. Autoloading is enabled by default. Official extensions available. HTTPFS is not available in DuckDB-Wasm. Extensions are signed. Extensions fetched from extensions.duckdb.org. Serving extensions from third-party repositories is supported. DuckDB-Wasm Instantiation: cdn, webpack, vite, or statically served. Instantiate AsyncDuckDB with worker and bundles (mainModule, mainWorker). DuckDB-Wasm: Runs in browsers. Limitations: Single-threaded by default. Limited memory (4GB). WASM Query API: connect() query() materialize send() lazy prepare(). Arrow to JSON: toArray().map(toJSON()). Export Parquet: COPY TO copyFileToBuffer(). Configuration options set using SET or PRAGMA statements. Values queried using current_setting() or duckdb_settings(). Scopes: GLOBAL and LOCAL. Global options include: memory_limit, threads, allow_community_extensions, custom_extension_repository, max_memory, s3_access_key_id, temp_directory. Local options include: enable_progress_bar, search_path, file_search_path, profile_output. Pragmas. PRAGMA statement for config/state. PRAGMA database_list list databases. PRAGMA show_tables list tables. PRAGMA show_tables_expanded expanded table list. PRAGMA functions list functions. PRAGMA table_info('table_name') table info. PRAGMA database_size database size. PRAGMA storage_info('table_name') storage info. PRAGMA show_databases show databases. SET memory_limit='1GB' set memory limit. SET threads=4 set threads. PRAGMA collations list collations. SET default_collation='nocase' set default collation. SET default_null_order='NULLS_FIRST' set null order. SET default_order='ASCENDING' set order direction. SET order_by_non_integer_literal=true allow non-int order by. SET old_implicit_casting=true old casting. SET python_scan_all_frames=true python scan all. PRAGMA version version. PRAGMA platform platform. PRAGMA user_agent user agent. PRAGMA metadata_info metadata. PRAGMA enable_progress_bar progress bar. SET explain_output='physical_only' explain output. PRAGMA enable_profiling enable profiling. SET enable_profiling='query_tree' profiling format. SET profiling_output='/path/to/file.json' profiling output file. SET profiling_mode='standard' profiling mode. SET custom_profiling_settings='{"CPU_TIME": "false"}' custom profiling. PRAGMA disable_profiling disable profiling. PRAGMA disable_optimizer disable optimizer. SET disabled_optimizers='filter_pushdown' disable optimizers. SET log_query_path='/tmp/duckdb_log/' log path. PRAGMA verify_external verify external. PRAGMA verify_serializer verify serializer. PRAGMA enable_verification verify. PRAGMA verify_parallelism parallelism. PRAGMA enable_object_cache object cache. PRAGMA force_checkpoint checkpoint. PRAGMA enable_checkpoint_on_shutdown checkpoint on shutdown. SET temp_directory='/path/to/temp_dir.tmp/' temp dir. SET errors_as_json=true errors as json. SET ieee_floating_point_ops=false ieee ops. SET default_block_size='16384' block size. Secrets Manager: Unified interface for secrets across backends (AWS S3, Azure, Cloudflare R2, GCS, Hugging Face, MySQL, PostgreSQL). Supports scoping (path prefixes) and persistence. Warning: Persistent secrets stored unencrypted. CREATE SECRET: Creates temporary secret. CREATE PERSISTENT SECRET: Creates persistent secret in ~/.duckdb/stored_secrets. SET secret_directory = 'path': Changes secrets directory. DROP SECRET: Deletes secret. DROP PERSISTENT SECRET my_persistent_secret;. Multiple secrets can exist per service type using scopes. FROM which_secret('path', 'type'): Returns secret being used. FROM duckdb_secrets(): Lists secrets (redacted). Concurrency: Single process R/W or multiple process R/O (access_mode). Single process: MVCC, optimistic concurrency. Multiple processes writing not directly supported, requires application logic (e.g., mutex, retries). Optimistic concurrency: Transaction conflict on same row edits. Workaround: Rerun transaction. Connect Overview: Connect to database to use DuckDB. Persistence: persistent (disk) or in-memory. Persistent: path to .duckdb file (creates if not exists). Backwards compatible storage v0.10+. In-memory: use ':memory:' or omit file, data lost on process end. Appender: Class for bulk data loading. Tied to connection transaction. Appender(con, table_name). AppendRow(values...). BeginRow(), Append(value), EndRow(). Flush(): manually flush cache. Close(): flush and close. Commit frequency: every 204800 rows or explicit transactions. Constraint Violations: PRIMARY KEY/UNIQUE error fails append. CSV Auto Detection: Detects dialect, types, and header. sniff_csv(filename, sample_size) -> CSV properties. Options: delim, quote, escape, new_line, skip, header, columns, dateformat, timestampformat, sample_size. Type detection: BOOLEAN, BIGINT, DOUBLE, TIME, DATE, TIMESTAMP, VARCHAR. Can override with types or all_varchar. Date/timestamp format: dateformat, timestampformat. Example: FROM sniff_csv('my_file.csv', sample_size = 1000). read_csv(file, options): Reads a CSV file. Options: all_varchar (BOOL), allow_quoted_nulls (BOOL), auto_detect (BOOL), auto_type_candidates (TYPE[]), columns (STRUCT), compression (VARCHAR), dateformat (VARCHAR), decimal_separator (VARCHAR), delimiter/delim/sep (VARCHAR), escape (VARCHAR), filename (BOOL), force_not_null (VARCHAR[]), header (BOOL), hive_partitioning (BOOL), ignore_errors (BOOL), max_line_size (BIGINT), names (VARCHAR[]), new_line (VARCHAR), normalize_names (BOOL), null_padding (BOOL), nullstr (VARCHAR or VARCHAR[]), parallel (BOOL), quote (VARCHAR), sample_size (BIGINT), skip (BIGINT), timestampformat (VARCHAR), types/dtypes (VARCHAR[] or STRUCT), union_by_name (BOOL). COPY statement: COPY table FROM file (options). Limitations: UTF-8 encoding only. preserve_insertion_order (BOOL, default true). Reading Faulty CSV Files: Detects and skips structural errors. Errors: CAST, MISSING COLUMNS, TOO MANY COLUMNS, UNQUOTED VALUE, LINE SIZE OVER MAXIMUM, INVALID UNICODE. ignore_errors=true skips error lines. CSV Rejects Table feature creates reject_scans and reject_errors tables (temporary). Parameters: store_rejects (BOOLEAN), rejects_scan (VARCHAR), rejects_table (VARCHAR), rejects_limit (BIGINT). Example: FROM read_csv('faulty.csv', columns={'name': 'VARCHAR', 'age': 'INTEGER'}, store_rejects = true); CSV Import Tips: read_csv(file, header=true/false, names=[...], types={col: type}). COPY table FROM 'file.csv'. union_by_name=true handles different schemas. Example: SELECT * FROM read_csv('flights.csv', header = true); Data Sources: Supports AWS S3, Azure Blob Storage, Cloudflare R2, CSV, Delta Lake, Excel, httpfs, Iceberg, JSON, MySQL, Parquet, PostgreSQL, SQLite. INSERT inefficient for bulk insertion. Avoid row-by-row inserts in loops. Maximize data per statement for bulk insert. For loop inserts, use BEGIN TRANSACTION and COMMIT to avoid auto-commit overhead. Syntax: INSERT INTO table_name VALUES (val1, val2), (val3, val4); Equality comparison of JSON files can differ. SELECT a != b, c != d, c[0] = d[0], a = c[0], b != c[0] FROM ( SELECT '[]'::JSON AS a, '[ ]'::JSON AS b, '[[]]'::JSON AS c, '[[ ]]'::JSON AS d ); JSON Creation Functions: to_json(any): Create JSON from value. LIST->JSON array, STRUCT/MAP->JSON object. json_quote(any): Alias for to_json. array_to_json(list): Alias for to_json (LIST only). row_to_json(list): Alias for to_json (STRUCT only). json_array([any, ...]): Create JSON array. json_object([key, value, ...]): Create JSON object. json_merge_patch(json, json): Merge JSON documents. Example: SELECT to_json([1, 2, 3]); JSON Format Settings: format='auto': infer format. format='newline_delimited': each line is JSON. Example: SELECT * FROM read_json('file.json', format='newline_delimited'). format='array': JSON array of objects. format='unstructured': JSON not newline-delimited/array. records='auto': infer records. records=true: unpack JSON objects to columns. Example: SELECT * FROM read_json('file.json', records=true). records=false: create STRUCTs. Example: SELECT * FROM read_json('file.json', records=false). INSTALL json; LOAD json: Installs and loads the JSON extension. JSON functions Extraction json_exists(json path) path exists json_extract(json path) -> JSON at path json_extract_string(json path) ->> VARCHAR at path json_value(json path) scalar JSON Scalar json_array_length(json [path]) array length json_contains(json_haystack json_needle) contains check json_keys(json [path]) object keys json_structure(json) structure json_type(json [path]) type json_valid(json) valid check json(json) parse minify Aggregate json_group_array(any) array aggregate json_group_object(key value) object aggregate json_group_structure(json) structure aggregate Transform json_transform(json structure) from_json(json structure) to nested types json_transform_strict(json structure) from_json_strict(json structure) strict transform error fail DuckDB supports JSON via the JSON logical type. JSON creation functions return JSON. Casting to/from JSON from other types is supported. VARCHAR to JSON parses and validates. read_json_objects(filename, compression='auto', filename=false, format='array', hive_partitioning=false, ignore_errors=false, maximum_sample_files=32, maximum_object_size=16777216): Read JSON objects from file. format=['unstructured', 'newline_delimited', 'array']. read_ndjson_objects(filename,...): alias format='newline_delimited'. read_json_objects_auto(filename,...): alias format='auto'. read_json(filename, auto_detect=false, columns={}, dateformat='iso', maximum_depth=-1, records='records', sample_size=20480, timestampformat='iso', union_by_name=false, map_inference_threshold=24, compression='auto', filename=false, format='array', hive_partitioning=false, ignore_errors=false, maximum_object_size=16777216): Read JSON as table. parameters: auto_detect, columns, dateformat, timestampformat, records, format, compression. read_json_auto(filename,...): alias auto-detect=true. read_ndjson(filename,...): alias format='newline_delimited'. read_ndjson_auto(filename,...): alias format='newline_delimited', auto-detect=true. COPY statement parameters similar to read_json. JSON: Supports reading and creating JSON. Indexing is 0-based. SELECT * FROM 'file.json'; read_json(); COPY (SELECT ...) TO 'file.json'; CREATE TABLE example (j JSON); INSERT INTO example VALUES ('{...}'); SELECT j.family FROM example; SELECT j->'$.family' FROM example; SELECT j->>\'$.family\' FROM example. json_deserialize_sql(json) -> VARCHAR: Deserializes JSON to SQL. json_execute_serialized_sql(varchar) -> TABLE: Executes JSON serialized SQL. json_serialize_sql(varchar, skip_empty := BOOLEAN, skip_null := BOOLEAN, format := BOOLEAN) -> VARCHAR: Serializes SQL to JSON. PRAGMA json_execute_serialized_sql(varchar): Pragma version of json_execute_serialized_sql. Exceptions: Transaction local changes not visible inside json_execute_serialized_sql if inside a transaction. Write JSON: COPY statement. See COPY docs. Combining Schemas: read_csv('files*.csv', union_by_name = true) reads multiple files, combining schemas. Default: combines by column position. union_by_name: combines by column name, missing values set to NULL. Increases memory consumption. Equivalent to UNION ALL BY NAME. Example: SELECT * FROM read_csv('flights*.csv'); SELECT * FROM read_csv('flights*.csv', union_by_name = true); Read multiple files: CSV, Parquet, JSON. SELECT * FROM 'dir/*.csv'; SELECT * FROM read_csv(['file1.csv', 'file2.csv'], union_by_name = true, filename = true); read_parquet(['file1.parquet', 'file2.parquet']); glob syntax: *, **, ? and []. Read multiple globs: read_parquet(['folder1/*.parquet', 'folder2/*.parquet']). Data Import: INSERT INTO, CSV, Parquet, JSON. CSV: SELECT * FROM 'file.csv'; SELECT * FROM read_csv('file.csv', header = false); COPY tbl FROM 'file.csv' (HEADER false). Parquet: SELECT * FROM 'file.parquet'; read_parquet(). JSON: SELECT * FROM 'file.json'; read_json_auto(). Appender: Efficient bulk loading (C, C++, Go, Java, Rust). Parquet Encryption: Supports reading/writing encrypted Parquet files. add_parquet_key(key_name, key_value): Adds encryption keys (128, 192, 256 bits). COPY ... (ENCRYPTION_CONFIG {footer_key: 'key'}): Writes encrypted files. COPY ... (ENCRYPTION_CONFIG {footer_key: 'key'}): Reads encrypted files. Limitations: Column encryption not supported. parquet_metadata(file_name VARCHAR): Queries Parquet file metadata. Returns: file_name, row_group_id, row_group_num_rows, row_group_num_columns, row_group_bytes, column_id, file_offset, num_values, path_in_schema, type, stats_min, stats_max, stats_null_count, stats_distinct_count, stats_min_value, stats_max_value, compression, encodings, index_page_offset, dictionary_page_offset, data_page_offset, total_compressed_size, total_uncompressed_size, key_value_metadata MAP(BLOB, BLOB). parquet_schema(file_name VARCHAR): Queries Parquet schema. Returns: file_name, name, type, type_length, repetition_type, num_children, converted_type, scale, precision, field_id, logical_type. parquet_file_metadata(file_name VARCHAR): Queries file-level metadata. Returns: file_name, created_by, num_rows, num_row_groups, format_version, encryption_algorithm, footer_signing_key_metadata. parquet_kv_metadata(file_name VARCHAR): Queries key-value metadata. Returns: file_name, key BLOB, value BLOB. read_parquet(path_or_list_of_paths) Reads Parquet file(s). Optional syntax if file ends in .parquet. Multiple files via glob or list. parquet_scan(path_or_list_of_paths) Alias for read_parquet. Options: binary_as_string (BOOL), encryption_config (STRUCT), filename (BOOL), file_row_number (BOOL), hive_partitioning (BOOL), union_by_name (BOOL). Inserts/Creates tables from Parquet. Create VIEW over read_parquet. COPY ... TO 'file.parquet' (FORMAT 'parquet', COMPRESSION, ROW_GROUP_SIZE, CODEC, KV_METADATA, etc.). EXPORT DATABASE 'target_directory' (FORMAT PARQUET). INSTALL parquet; (extension) Parquet Tips: Reading: union_by_name unifies schema of files. Writing: PER_THREAD_OUTPUT for performance, ROW_GROUP_SIZE (min 2048, default 122880) for compression/query speed, ROW_GROUPS_PER_FILE for splitting files. Hive Partitioning: Splits tables into files based on partition keys and folders. SELECT * FROM read_parquet('path', hive_partitioning = true); reads partitioned data, including partition columns. COPY table TO 'path' (FORMAT PARQUET, PARTITION_BY (col1, col2)); writes partitioned data. Partition columns from directory structure. Filters on partition keys pushed down. SET hive_partitioning = false; disables auto-detection. hive_types: Specify logical types of hive partitions. SELECT * FROM read_parquet('path', hive_partitioning = true, hive_types = {'col': DATE}); SET hive_types_autocast = 0; disables type auto-detection. Partitioned Writes. COPY table TO 'path' (FORMAT format, PARTITION_BY (col1, col2), ...). Options: FORMAT (PARQUET, CSV), PARTITION_BY, OVERWRITE_OR_IGNORE, COMPRESSION, FILE_EXTENSION, FILENAME_PATTERN '{i}' '{uuid}'. Writes files to Hive partitioned hierarchy. Default filename: data_i.format. Many small partitions can be expensive. Recommend >100MB/partition. OVERWRITE_OR_IGNORE allows overwriting directories. Benchmark Suite: Used to detect performance regressions. Commands: - BUILD_BENCHMARK=1 CORE_EXTENSIONS='tpch' make: Builds the benchmark suite. - build/release/benchmark/benchmark_runner --list: Lists all available benchmarks. - build/release/benchmark/benchmark_runner [benchmark_file]: Runs a single benchmark. Output is CSV. Use --out=[file] to write timings. - build/release/benchmark/benchmark_runner "[regex]": Runs benchmarks matching regex. - build/release/benchmark/benchmark_runner: Runs all benchmarks. - build/release/benchmark/benchmark_runner [benchmark_file] --info: Shows benchmark information. - build/release/benchmark/benchmark_runner [benchmark_file] --query: Prints the query run by the benchmark. - build/release/benchmark/benchmark_runner [benchmark_file] --profile: Outputs a query tree. Build Types: release (optimized performance), debug (debug symbols, slow), relassert (debug symbols, faster), reldebug (no assertions), benchmark (release + BUILD_BENCHMARK), tidy-check (clang-tidy check), format-fix/changes/main (format checks). Package Flags: BUILD_PYTHON, BUILD_SHELL, BUILD_BENCHMARK, BUILD_JDBC, BUILD_ODBC (enable package builds). Misc Flags: DISABLE_UNITY (disable unity build), DISABLE_SANITIZER (disable sanitizers), OVERRIDE_GIT_DESCRIBE (override git hash/version). Building Extensions. Build extensions using build flags: CORE_EXTENSIONS='ext1 ext2' make. Special flags: BUILD_JEMALLOC, BUILD_TPCE. Debug flags: CRASH_ON_ASSERT, DISABLE_STRING_INLINE, DISABLE_MEMORY_SAFETY, DESTROY_UNPINNED_BLOCKS, DEBUG_STACKTRACE. CMake config file: extension_config.cmake with duckdb_extension_load(extension_name). Build command: EXTENSION_CONFIGS="extension_config.cmake" make. Install extensions: cd build/{release/debug}/extension/; for EXTENSION in *; do ../duckdb -c "INSTALL '${EXTENSION}/${EXTENSION}.duckdb_extension';"; done Build: CMake C++11 compiler Ninja recommended. UNIX Windows Raspberry Pi. Build command: make GEN=ninja. Extensions: CORE_EXTENSIONS="..." make. Memory issues: GEN=make. Building DuckDB from Source: Build DuckDB under specific circumstances (architecture or unmerged pull request). Supported Platforms: linux_amd64, linux_arm64, osx_amd64, osx_arm64, windows_amd64, windows_arm64. Other Platforms: freebsd_amd64, freebsd_arm64, linux_arm64_android, linux_arm64_gcc4, wasm_eh, wasm_mvp, windows_amd64_mingw, windows_amd64_rtools, windows_arm64_mingw. 32-bit not officially supported. Troubleshooting: R Package: Compilation uses single thread: Edit ~/.R/Makevars, add MAKEFLAGS = -j$(nproc) for parallel compilation. Linux AArch64: "too many GOT entries" error: Edit ~/.R/Makevars, add ALL_CXXFLAGS = $(PKG_CXXFLAGS) -fPIC $(SHLIB_CXXFLAGS) $(CXXFLAGS). Python Package: "No module named 'duckdb.duckdb'": Change directory. Python Package macOS: httpfs build fails: Build httpfs separately, then install Python package. Linux: httpfs build fails: Install libssl-dev, then build. Profiling: EXPLAIN: Show query plan. EXPLAIN ANALYZE: Show query plan, execute query, show performance. Pragmas: enable_profiling/enable_profile: Turn on profiling. profiling_output: Set output file. profiling_mode: Toggle optimizer metrics (standard, detailed). custom_profiling_settings: Enable specific metrics (JSON). disable_profiling/disable_profile: Turn off. Metrics: BLOCKED_THREAD_TIME, EXTRA_INFO, LATENCY, OPERATOR_CARDINALITY, OPERATOR_ROWS_SCANNED, OPERATOR_TIMING, OPERATOR_TYPE, QUERY_NAME, RESULT_SET_SIZE, ROWS_RETURNED. Cumulative Metrics: CPU_TIME, CUMULATIVE_CARDINALITY, CUMULATIVE_ROWS_SCANNED. Detailed Profiling: profiling_mode=detailed enables OPTIMIZER, PLANNER, PHYSICAL_PLANNER metrics. Optimizer Metrics: OPTIMIZER_⟨OPTIMIZER_NAME⟩, ALL_OPTIMIZERS, CUMMULATIVE_OPTIMIZER_TIMING. Planner Metrics: PLANNER, PLANNER_BINDING. Physical Planner Metrics: PHYSICAL_PLANNER, PHYSICAL_PLANNER_COLUMN_BINDING, PHYSICAL_PLANNER_RESOLVE_TYPES, PHYSICAL_PLANNER_CREATE_PLAN. Query Graphs: python -m duckdb.query_graph /path/to/file.json Release calendar for DuckDB. Semantic versioning. Patch versions: bugfixes. Minor versions: new features. DuckDB Repositories: duckdb (core), duckdb-wasm, duckdb-web, clients (duckdb-java, duckdb-node, duckdb-odbc, duckdb-r, duckdb-rs, duckdb-swift), connectors (dbt-duckdb, duckdb_mysql, pg_duckdb, postgres_scanner, sqlite_scanner). Extensions: Core Extensions (linked on Official Extensions page), Community Extensions. Catch C++ Tests: Describes how to write C++ tests using Catch2 framework for testing C++ API. Debugging: Use debug mode (make debug). Run specific tests via filename. Breakpoints: query_break(line). Skipping queries: mode skip/unskip. Triggering tests: unittest [directory], unittest *, unittest --start-offset=N --end-offset=M, unittest -f test.list sqllogictest: Tests SQL statements with expected results/errors. Located in test/sql directory. Use --test-dir <root_directory> to specify other test directories. Structure: # name: test_file_path # group [group_name] statement ok SQL_statement query column_types SELECT_query ---- expected_results (tab separated) statement ok: Statement expected to succeed. query column_types: Query with column types (e.g. II for two INTEGER columns) SELECT_query: SQL query to execute ---- expected_results: Tab-separated expected results. PRAGMA enable_verification: Enables query verification (runs optimized and unoptimized queries, compares results). __TEST_DIR__: Placeholder for temporary testing directory path. require extension_name: Skips test if extension is not loaded. require vector_size size: Skips test unless vector size is at least size. unittest test_file_path: Run single test file. unittest "[group_name]": Run all tests in group. Loops in sqllogictests: loop var start end ... endloop - query iteration; foreach var val1 val2 ... ... endloop - value iteration. Preset Expansion: compression, signed, unsigned, integral, numeric, alltypes. Use loops sparingly. Data Generation: use range(), repeat(), random(), CSV/Parquet files, TPC-H/TPC-DS instead of loops for data. Multiple Connections: Use connection labels for transactional/versioning tests. Example: statement ok con1 BEGIN TRANSACTION; statement ok con1 CREATE TABLE integers (...); statement error con2 SELECT * FROM integers;. Concurrent Connections: concurrentloop for concurrent execution. Use statement maybe for unpredictable results. DuckDB testing overview. Tests run on commits and pull requests. Uses a fuzzer, SQLsmith. Persistent Testing: load [db_file] loads DB, restart reloads it. Tests run with SET wal_autocheckpoint = '0KB'. WAL tests use PRAGMA disable_checkpoint_on_shutdown; PRAGMA wal_autocheckpoint = '1TB'. Result Verification: query I[I...] SELECT ...; ---- result1 result2 ... NULL values: NULL string. Empty strings: (empty). Error Verification: statement error SELECT ...; ---- error message. Regex: :.*pattern.*, :.*pattern.* File: :path/to/file. Row-Wise vs. Value-Wise: Result order. Hashes: query I SELECT ...; ---- values hashing to hash. mode output_hash: Print expected hashes. mode output_result: Print results. Result Sorting: nosort, rowsort, valuesort. Query Labels: query I label SELECT ...; ---- DuckDB testing uses SQL via sqllogictest framework. Avoid testing components individually. test_all_types(): Generates a table with columns for each type (BOOL, TINYINT, etc.) and min, max, and null values. test_vector_types(col1, ..., coln, all_flat BOOLEAN): Generates a table with n columns test_vector1, ..., test_vectorn, conforming to column types. all_flat affects internal representation. FROM test_all_types(); FROM test_vector_types(NULL::BIGINT); Arrow Extension: Integrates Apache Arrow. to_arrow_ipc(table) -> IPC buffers. scan_arrow_ipc(pointers) -> table. AutoComplete Extension: Adds autocomplete in CLI. Function: sql_auto_complete(query_string): Autocomplete query; returns suggestion. Example: SELECT * FROM sql_auto_complete('SEL'). aws extension adds functionality on top of httpfs for S3 using the AWS SDK. INSTALL aws; LOAD aws installs and loads. load_aws_credentials PRAGMA function loads AWS credentials. Deprecated load_aws_credentials('profile', set_region = false, redact_secret = false) takes optional parameters. Azure Extension: Adds Azure Blob storage filesystem abstraction. Supports az://, azure://, abfss:// URI schemes. Authentication: CONFIG, CREDENTIAL_CHAIN, SERVICE_PRINCIPAL. Configuration via SET variables or CREATE SECRET. SET azure_http_stats, azure_read_transfer_concurrency, azure_read_transfer_chunk_size, azure_read_buffer_size, azure_transport_option_type, azure_context_caching. CREATE SECRET: TYPE AZURE, PROVIDER (CONFIG, CREDENTIAL_CHAIN, SERVICE_PRINCIPAL), ACCOUNT_NAME, CONNECTION_STRING, TENANT_ID, CLIENT_ID, CLIENT_SECRET, CLIENT_CERTIFICATE_PATH, HTTP_PROXY, PROXY_USER_NAME, PROXY_PASSWORD. AZURE_LOG_LEVEL environment variable for logging. Community Extensions: User-contributed extensions. INSTALL extension_name FROM community; LOAD extension_name; Example: INSTALL h3 FROM community; LOAD h3; Checks: Signature verified on load. Supported Platforms: Linux, macOS, Windows, WebAssembly. Requires DuckDB 1.0.0+. Developer Experience: 1. PR with description.yml. 2. CI builds and tests. extension: name: h3 description: Hierarchical hexagonal indexing version: 1.0.0 language: C++ build: cmake license: Apache-2.0 maintainers: - isaacbrodsky repo: github: isaacbrodsky/h3-duckdb ref: commit_hash Security Considerations: See Securing Extensions page. Core Extensions: Extends DuckDB functionality. arrow: Zero-copy data integration with Apache Arrow. autocomplete: Autocomplete in shell. aws: AWS SDK features. azure: Azure Blob Storage filesystem. delta: Delta Lake support. excel: Excel format strings. fts: Full-Text Search Indexes. httpfs: HTTP(S)/S3 file reading/writing. Aliases: http, https, s3. iceberg: Apache Iceberg support. icu: Time zones and collations (ICU library). inet: IP data types/functions. jemalloc: Replaces system allocator. json: JSON operations. mysql: MySQL read/write. parquet: Parquet read/write (built-in). postgres: PostgreSQL read/write. Alias: postgres_scanner. spatial: Geospatial data/functions. sqlite: SQLite read/write. Aliases: sqlite_scanner, sqlite3. substrait: Substrait integration. tpcds: TPC-DS data generation/query. tpch: TPC-H data generation/query. vss: Vector similarity search queries. Default Extensions: Varies by client (CLI, Python, R, Java, Node.js). jemalloc availability: OS-dependent; built-in on Linux x86_64 from 0.10.1. Delta Extension: Adds Delta Lake support. Experimental. INSTALL delta; LOAD delta; delta_scan(path): Scans a Delta table. path: Path to Delta table (local/S3/Azure). Example: SELECT * FROM delta_scan('s3://some/delta/table'); S3 Authentication: Use DuckDB Secrets. CREATE SECRET (TYPE S3, PROVIDER CREDENTIAL_CHAIN); Region: CREATE SECRET (TYPE S3, REGION 'my-region'); Azure Authentication: CREATE SECRET (TYPE AZURE, PROVIDER CREDENTIAL_CHAIN); Supported Platforms: Linux AMD64/ARM64, macOS Intel/Apple Silicon, Windows AMD64. Requires DuckDB 0.10.3+. excel extension: number formatting per Excel rules. Functions: excel_text(number, format_string), text(number, format_string) (alias). Install/Load: INSTALL excel; LOAD excel; Example: SELECT excel_text(1234567.897, 'h:mm AM/PM'). Excel file handling via spatial extension. Full-Text Search Extension for string searching. Install/Load: INSTALL fts; LOAD fts;. PRAGMA create_fts_index(input_table, input_id, *input_values, stemmer='porter', stopwords='english', ignore='(\\\\.|[^a-z])+', strip_accents=1, lower=1, overwrite=0): creates FTS index. PRAGMA drop_fts_index(input_table): drops FTS index. Function match_bm25(input_id, query_string, fields=NULL, k=1.2, b=0.75, conjunctive=0): searches index. Function stem(input_string, stemmer): reduces words to base form. Index update: manual refresh required after table changes. httpfs extension: query files over HTTP(S). Read-only access. Partial read Parquet. Scan multiple files. Custom certs (nightly). Usage: SELECT * FROM 'https://...'; SELECT column_a FROM 'https://...'; SELECT count(*) FROM 'https://...'; SELECT * FROM read_parquet(['https://...', 'https://...']). Cert config: LOAD httpfs; SET ca_cert_file=''; SET enable_server_cert_verification=true;. hf:// protocol for Hugging Face repositories. Query: hf://datasets/⟨my_username⟩/⟨my_dataset⟩/⟨path_to_file⟩. Example: SELECT * FROM 'hf://datasets/datasets-examples/doc-formats-csv-1/data.csv'. CREATE TABLE ... AS to save data. Glob patterns supported. Versioning: hf://datasets/⟨my-username⟩/⟨my-dataset⟩@⟨my_branch⟩/⟨path_to_file⟩. Authentication via Hugging Face Token in DuckDB Secrets Manager. httpfs Extension: Allows reading/writing remote files via HTTP(S) and S3. Install: INSTALL httpfs; LOAD httpfs. httpfs extension: S3 API support for reading/writing/globbing files on object storage. Supported platforms: AWS S3, Minio, Google Cloud, lakeFS, Cloudflare R2. Configuration and Authentication: Secrets manager is preferred. CONFIG Provider: Manual key configuration. CREATE SECRET secret1 (TYPE S3, KEY_ID '...', SECRET '...', REGION '...'); CREDENTIAL_CHAIN Provider: Auto-fetches credentials. CREATE SECRET secret2 (TYPE S3, PROVIDER CREDENTIAL_CHAIN); CHAIN: Specifies provider order (e.g., CHAIN 'env;config'). Values: config, sts, sso, env, instance, process Secret Parameters: KEY_ID, SECRET, REGION (default us-east-1), SESSION_TOKEN, ENDPOINT (default s3.amazonaws.com), URL_STYLE (vhost/path), USE_SSL (true), URL_COMPATIBILITY_MODE (true), ACCOUNT_ID (R2) R2 Secrets: TYPE R2, ACCOUNT_ID required. Uses r2:// URLs. GCS Secrets: TYPE GCS. Uses gcs:// or gs:// URLs. Reading: SELECT * FROM 's3://bucket/file.extension'; Partial Reading: Supported. Multiple Files: SELECT * FROM read_parquet(['s3://bucket/file1.parquet', 's3://bucket/file2.parquet']); Globbing: SELECT * FROM read_parquet('s3://bucket/*.parquet'); filename=true option adds filename column. Hive Partitioning: Supported. Writing: COPY table_name TO 's3://bucket/file.extension'; Uses multipart upload. Partitioned Copy: COPY table TO 's3://my-bucket/partitioned' (FORMAT PARQUET, PARTITION_BY (part_col_a, part_col_b)); OVERWRITE_OR_IGNORE true: Disables checks for existing files. Configuration Options: s3_uploader_max_parts_per_file, s3_uploader_max_filesize, s3_uploader_thread_limit S3 Legacy Authentication: SET s3_region; SET s3_endpoint; SET s3_use_ssl; SET s3_url_style; SET s3_access_key_id; SET s3_secret_access_key; SET s3_session_token; Per-request config via URI params (e.g. ?s3_access_key_id=... ). INSTALL iceberg; LOAD iceberg; iceberg_scan(table_path, allow_moved_paths); iceberg_scan(manifest_path); iceberg_metadata(table_path, allow_moved_paths); iceberg_snapshots(table_path). Writing not supported. ICU Extension: Provides collation/timezone functionality. INSTALL icu; LOAD icu; Features: region-dependent collations, time zones for timestamp data types. inet extension: INET data type for IPv4/IPv6 addresses, CIDR notation. Install: INSTALL inet; LOAD inet;. Operations: comparison, +/- integers. HOST(inet) function: extracts host component. HTML_ESCAPE(str), HTML_UNESCAPE(str) functions available. jemalloc Extension: Memory allocator. Statically linked, OS-dependent (Linux AMD64 default, ARM64/macOS opt). SET allocator_background_threads = true for threads. MySQL Extension: Reads/writes data from/to MySQL. INSTALL mysql: Installs the extension. LOAD mysql: Loads the extension. ATTACH 'connection_string' AS alias (TYPE MYSQL): Attaches to MySQL. CREATE SECRET (TYPE MYSQL, ...): Creates a secret for connection. mysql_query(attached_database::VARCHAR, query::VARCHAR) -> TABLE: Runs read queries in MySQL. mysql_execute(attached_database::VARCHAR, query::VARCHAR): Runs arbitrary queries in MySQL. mysql_clear_cache(): Clears schema cache. Settings: mysql_bit1_as_boolean, mysql_debug_show_queries, mysql_experimental_filter_pushdown, mysql_tinyint1_as_boolean. Supported operations: CREATE TABLE, INSERT INTO, SELECT, COPY, UPDATE, DELETE, ALTER TABLE, DROP TABLE, CREATE VIEW, CREATE/DROP SCHEMA, Transactions. Extensions: Dynamically loadable modules. duckdb_extensions(): Lists extensions (name, installed, description). INSTALL/LOAD: Explicitly install and load. Autoloading: Some extensions load automatically. UPDATE EXTENSIONS: Updates installed extensions. Extension location: ~/.duckdb/extensions/ Use -unsigned flag or allow_unsigned_extensions for unsigned extensions. PostgreSQL Extension: Read/write PostgreSQL data. Install: INSTALL postgres; LOAD postgres;. Connect: ATTACH '' AS db (TYPE POSTGRES); ATTACH 'conn_str' AS db (TYPE POSTGRES, READ_ONLY);. Config: connection string, URI, secrets (CREATE SECRET), env vars (PG*). Usage: Read PostgreSQL tables as DuckDB tables. SHOW ALL TABLES; SELECT * FROM table;. Copy: CREATE TABLE duckdb_table AS FROM postgres_db.postgres_tbl;. Write: CREATE TABLE postgres_db.tbl (...); INSERT INTO postgres_db.tbl VALUES (...);. Operations: CREATE TABLE, INSERT, SELECT, COPY, UPDATE, DELETE, ALTER TABLE, DROP TABLE, CREATE VIEW, CREATE/DROP SCHEMA, DETACH, Transactions (BEGIN, ROLLBACK). Functions: postgres_query(db_name, query) - read queries; postgres_execute(db_name, query) - all queries. Settings: pg_array_as_varchar, pg_connection_cache, pg_connection_limit, pg_debug_show_queries, pg_experimental_filter_pushdown, pg_pages_per_task, pg_use_binary_copy, pg_null_byte_replacement, pg_use_ctid_scan. Schema Cache: pg_clear_cache() - clear cache. Deprecated: postgres_attach - use ATTACH. Scalar Functions: ST_Area(GEOMETRY): DOUBLE - Compute area of geometry. ST_Area_Spheroid(GEOMETRY): DOUBLE - Area in meters, ellipsoidal earth model. ST_AsGeoJSON(GEOMETRY): JSON - Geometry as GeoJSON fragment. ST_AsHEXWKB(GEOMETRY): VARCHAR - Geometry as HEXWKB string. ST_AsSVG(GEOMETRY, BOOLEAN, INTEGER): VARCHAR - Geometry to SVG fragment/path. ST_AsText(GEOMETRY): VARCHAR - Geometry as WKT string. ST_AsWKB(GEOMETRY): WKB_BLOB - Geometry as WKB blob. ST_Boundary(GEOMETRY): GEOMETRY - Returns geometry boundary. ST_Buffer(GEOMETRY, DOUBLE, INTEGER, VARCHAR, VARCHAR, DOUBLE): GEOMETRY - Buffer around geometry. join_style: "JOIN_ROUND", "JOIN_MITRE", "JOIN_BEVEL". cap_style: "CAP_ROUND", "CAP_FLAT", "CAP_SQUARE" ST_Centroid(GEOMETRY): POINT_2D/GEOMETRY - Calculate geometry centroid. ST_Collect(GEOMETRY[]): GEOMETRY - Collect geometries into a collection. Returns MULTIPOINT, MULTILINESTRING, MULTIPOLYGON, or GEOMETRYCOLLECTION. ST_CollectionExtract(GEOMETRY, INTEGER): GEOMETRY - Extracts geometries from GeometryCollection. Type: 1=Point, 2=LineString, 3=Polygon. ST_Contains(GEOMETRY, GEOMETRY): BOOLEAN - True if geom1 contains geom2. ST_ContainsProperly(GEOMETRY, GEOMETRY): BOOLEAN - True if geom1 properly contains geom2. ST_ConvexHull(GEOMETRY): GEOMETRY - Convex hull enclosing geometry. ST_CoveredBy(GEOMETRY, GEOMETRY): BOOLEAN - True if geom1 is covered by geom2. ST_Covers(GEOMETRY, GEOMETRY): BOOLEAN - True if geom1 covers geom2. ST_Crosses(GEOMETRY, GEOMETRY): BOOLEAN - True if geom1 crosses geom2. ST_DWithin(GEOMETRY, GEOMETRY, DOUBLE): BOOLEAN - True if geometries are within distance. ST_DWithin_Spheroid(POINT_2D, POINT_2D, DOUBLE): DOUBLE - Distance in meters, ellipsoidal earth. ST_Difference(GEOMETRY, GEOMETRY): GEOMETRY - Difference between geometries. ST_Dimension(GEOMETRY): INTEGER - Dimension of geometry. ST_Disjoint(GEOMETRY, GEOMETRY): BOOLEAN - True if geometries are disjoint. ST_Distance(GEOMETRY, GEOMETRY): DOUBLE - Distance between geometries. ST_Distance_Sphere(GEOMETRY, GEOMETRY): DOUBLE - Haversine distance, POINT geometries only, meters. ST_Distance_Spheroid(POINT_2D, POINT_2D): DOUBLE - Distance in meters, ellipsoidal earth. ST_Dump(GEOMETRY): STRUCT(geom GEOMETRY, path INTEGER[])[] - Dumps geometry into sub-geometries/paths. ST_EndPoint(GEOMETRY): GEOMETRY/POINT_2D - Last point of a line. ST_Envelope(GEOMETRY): GEOMETRY - Minimum bounding box as polygon. ST_Equals(GEOMETRY, GEOMETRY): BOOLEAN - True if geometries are equal. ST_Extent(GEOMETRY): BOX_2D - Minimal bounding box. ST_ExteriorRing(GEOMETRY): LINESTRING_2D/GEOMETRY - Exterior ring of a polygon. ST_FlipCoordinates(GEOMETRY): GEOMETRY - Flips x and y coordinates. ST_Force2D(GEOMETRY): GEOMETRY - Forces X and Y components, drops Z/M. ST_Force3DM(GEOMETRY, DOUBLE): GEOMETRY - Forces X, Y, and M components. ST_Force3DZ(GEOMETRY, DOUBLE): GEOMETRY - Forces X, Y, and Z components. ST_Force4D(GEOMETRY, DOUBLE, DOUBLE): GEOMETRY - Forces X, Y, Z, and M components. ST_GeomFromGeoJSON(VARCHAR/JSON): GEOMETRY - Deserializes from GeoJSON. ST_GeomFromHEXEWKB(VARCHAR): GEOMETRY - Deserializes from HEXEWKB. ST_GeomFromHEXWKB(VARCHAR): GEOMETRY - Creates from HEXWKB string. ST_GeomFromText(VARCHAR, BOOLEAN): GEOMETRY - Deserializes from WKT string. ST_GeomFromWKB(WKB_BLOB/BLOB): GEOMETRY - Deserializes from WKB blob. ST_GeometryType(GEOMETRY): ANY - Returns 'GEOMETRY_TYPE' enum. ST_HasM(GEOMETRY): BOOLEAN - True if geometry has M values. ST_HasZ(GEOMETRY): BOOLEAN - True if geometry has Z values. ST_Hilbert(DOUBLE, DOUBLE, BOX_2D): UINTEGER - Encodes X/Y as Hilbert curve index. ST_Intersection(GEOMETRY, GEOMETRY): GEOMETRY - Intersection of geom1 and geom2. ST_Intersects(GEOMETRY, GEOMETRY): BOOLEAN - True if geometries intersect. ST_Intersects_Extent(GEOMETRY, GEOMETRY): BOOLEAN - True if extents intersect. ST_IsClosed(GEOMETRY): BOOLEAN - True if geometry is closed. ST_IsEmpty(GEOMETRY): BOOLEAN - True if geometry is empty. ST_IsRing(GEOMETRY): BOOLEAN - True if line geometry is a ring. ST_IsSimple(GEOMETRY): BOOLEAN - True if geometry is simple. ST_IsValid(GEOMETRY): BOOLEAN - True if geometry is topologically valid. ST_Length(GEOMETRY): DOUBLE - Length of line geometry. ST_Length_Spheroid(GEOMETRY): DOUBLE - Length in meters, ellipsoidal earth. ST_LineMerge(GEOMETRY, BOOLEAN): GEOMETRY - Merges line geometry. ST_M(GEOMETRY): DOUBLE - M value of a point. ST_MMax(GEOMETRY): DOUBLE - Maximum M value. ST_MMin(GEOMETRY): DOUBLE - Minimum M value. ST_MakeEnvelope(DOUBLE, DOUBLE, DOUBLE, DOUBLE): GEOMETRY - Bounding box polygon. ST_MakeLine(GEOMETRY[]/GEOMETRY, GEOMETRY): GEOMETRY - Creates LINESTRING from points. ST_MakePolygon(GEOMETRY, GEOMETRY[]): GEOMETRY - Creates polygon from shell/holes. ST_MakeValid(GEOMETRY): GEOMETRY - Attempts to make geometry valid. ST_Multi(GEOMETRY): GEOMETRY - Turns single geometry into multi geometry. ST_NGeometries(GEOMETRY): INTEGER - Number of component geometries. ST_NInteriorRings(GEOMETRY): INTEGER - Number of interior rings of a polygon. ST_NPoints(GEOMETRY): UBIGINT/UINTEGER - Number of vertices in geometry. ST_Normalize(GEOMETRY): GEOMETRY - Returns normalized geometry. ST_NumGeometries(GEOMETRY): INTEGER - Number of component geometries. ST_NumInteriorRings(GEOMETRY): INTEGER - Number of interior rings of a polygon. ST_NumPoints(GEOMETRY): UBIGINT/UINTEGER - Number of vertices in geometry. ST_Overlaps(GEOMETRY, GEOMETRY): BOOLEAN - True if geom1 overlaps geom2. ST_Perimeter(GEOMETRY): DOUBLE - Perimeter length. ST_Perimeter_Spheroid(GEOMETRY): DOUBLE - Perimeter in meters, ellipsoidal earth. ST_Point(DOUBLE, DOUBLE): GEOMETRY - Creates a GEOMETRY point ST_Point2D(DOUBLE, DOUBLE): POINT_2D - Creates a POINT_2D ST_Point3D(DOUBLE, DOUBLE, DOUBLE): POINT_3D - Creates a POINT_3D ST_Point4D(DOUBLE, DOUBLE, DOUBLE, DOUBLE): POINT_4D - Creates a POINT_4D ST_PointN(GEOMETRY, INTEGER): GEOMETRY/POINT_2D - N'th vertex as point. ST_PointOnSurface(GEOMETRY): GEOMETRY - Point on the surface. ST_Points(GEOMETRY): GEOMETRY - Collects vertices into multipoint. ST_QuadKey(DOUBLE, DOUBLE, INTEGER): VARCHAR - Quadkey for lon/lat at level. ST_ReducePrecision(GEOMETRY, DOUBLE): GEOMETRY - Geometry with reduced precision. ST_RemoveRepeatedPoints(GEOMETRY, DOUBLE): GEOMETRY/LINESTRING_2D - Removes repeated points. ST_Reverse(GEOMETRY): GEOMETRY - Reverses vertex order. ST_ShortestLine(GEOMETRY, GEOMETRY): GEOMETRY - Line between closest points. ST_Simplify(GEOMETRY, DOUBLE): GEOMETRY - Simplifies by collapsing edges. ST_SimplifyPreserveTopology(GEOMETRY, DOUBLE): GEOMETRY - Simplifies, preserves topology. ST_StartPoint(GEOMETRY): GEOMETRY/POINT_2D - First point of a line. ST_Touches(GEOMETRY, GEOMETRY): BOOLEAN - True if geom1 touches geom2. ST_Transform(GEOMETRY, VARCHAR, VARCHAR, BOOLEAN): GEOMETRY/BOX_2D/POINT_2D - Transforms between coordinate systems. ST_Union(GEOMETRY, GEOMETRY): GEOMETRY - Union of two geometries. ST_Within(GEOMETRY, GEOMETRY): BOOLEAN - True if geom1 is within geom2. ST_X(GEOMETRY): DOUBLE - X value of a point. ST_XMax(GEOMETRY): DOUBLE/FLOAT - Maximum X value. ST_XMin(GEOMETRY): DOUBLE/FLOAT - Minimum X value. ST_Y(GEOMETRY): DOUBLE - Y value of a point. ST_YMax(GEOMETRY): DOUBLE/FLOAT - Maximum Y value. ST_YMin(GEOMETRY): DOUBLE/FLOAT - Minimum Y value. ST_Z(GEOMETRY): DOUBLE - Z value of a point. ST_ZMFlag(GEOMETRY): UTINYINT - Flag for Z/M presence (0=none, 1=M, 2=Z, 3=Z/M). ST_ZMax(GEOMETRY): DOUBLE - Maximum Z value. ST_ZMin(GEOMETRY): DOUBLE - Minimum Z value. Aggregate Functions: ST_Envelope_Agg(GEOMETRY): GEOMETRY - Alias for ST_Extent_Agg. ST_Extent_Agg(GEOMETRY): GEOMETRY - Minimal-bounding-box polygon. ST_Intersection_Agg(GEOMETRY): GEOMETRY - Intersection of geometries. ST_Union_Agg(GEOMETRY): GEOMETRY - Union of geometries. Table Functions: ST_Drivers(): Returns list of supported GDAL drivers and formats. ST_Read(VARCHAR, BOOLEAN, INTEGER, BOOLEAN, VARCHAR, VARCHAR[], WKB_BLOB, BOX_2D, VARCHAR[], VARCHAR[]): Reads geospatial file formats using GDAL. ST_ReadOSM(VARCHAR): Reads OpenStreetMap data from .osm.pbf file. ST_Read_Meta(VARCHAR/VARCHAR[]): Reads metadata from geospatial file formats using GDAL. GDAL integration for spatial data. COPY ⟨table⟩ TO 'path/filename.geojson' WITH (FORMAT GDAL, DRIVER 'GeoJSON', LAYER_CREATION_OPTIONS 'WRITE_BBOX=YES'); FORMAT: GDAL (required). DRIVER: GDAL driver (use ST_Drivers()). LAYER_CREATION_OPTIONS: GDAL driver options. SRS: Spatial reference system metadata. Only vector drivers are supported. Spatial Extension provides geospatial data processing. Install: INSTALL spatial; LOAD spatial;. GEOMETRY Type: binary spatial data representation. Subtypes: POINT, LINESTRING, POLYGON, MULTIPOINT, MULTILINESTRING, MULTIPOLYGON, GEOMETRYCOLLECTION. Based on Simple Features geometry model. Experimental types: POINT_2D, LINESTRING_2D, POLYGON_2D, BOX_2D (nested types). GEOMETRY recommended for general use. Limitations: no curved geometries, SRID per value. R-Tree indexes accelerate spatial queries. Supported for GEOMETRY type. Used with ST_Equals, ST_Intersects, ST_Touches, ST_Crosses, ST_Within, ST_Contains, ST_Overlaps, ST_Covers, ST_CoveredBy, ST_ContainsProperly in WHERE clause. CREATE INDEX my_idx ON my_table USING RTREE (geom) WITH (max_node_capacity = 16); Options: max_node_capacity, min_node_capacity. rtree_index_dump(VARCHAR) returns R-tree nodes. Bulk loading is faster than creating index then inserting. Index resides in memory once scanned. SQLite Extension: Reads/writes SQLite database files. INSTALL sqlite; LOAD sqlite; ATTACH 'sakila.db' (TYPE SQLITE); USE sakila; Tables accessible as DuckDB tables. Type mapping: INT -> BIGINT, CHAR/CLOB/TEXT -> VARCHAR, BLOB -> BLOB, REAL/FLOA/DOUB/DEC/NUM -> DOUBLE, DATE -> DATE, TIME -> TIMESTAMP, other -> VARCHAR. SET GLOBAL sqlite_all_varchar = true; converts all columns to VARCHAR. Can open SQLite files directly: duckdb sakila.db. Writing to SQLite supported: CREATE TABLE sqlite_db.tbl; INSERT INTO sqlite_db.tbl VALUES. Operations: CREATE TABLE, INSERT, SELECT, COPY, UPDATE, DELETE, ALTER TABLE, DROP TABLE, CREATE VIEW, Transactions. Concurrency: handled by SQLite. Deprecated: sqlite_attach. sqlsmith extension: for testing. Install: INSTALL sqlsmith; LOAD sqlsmith;. Functions: sqlsmith(), fuzzyduck(), reduce_sql_statement(), fuzz_all_functions(). Substrait Extension: Supports Substrait query plans. APIs: SQL, Python, R. Requires permission for support. Installation: INSTALL substrait; LOAD substrait; SQL API: get_substrait(sql): Returns Substrait BLOB for SQL query. get_substrait_json(sql): Returns JSON representation of Substrait plan. from_substrait(blob): Executes Substrait BLOB plan. Python API: con.install_extension("substrait"); con.load_extension("substrait"); con.get_substrait(query=sql): Returns Substrait BLOB. con.get_substrait_json(sql): Returns JSON. con.from_substrait(proto=blob): Executes BLOB. R API: library("duckdb"); dbExecute(con, "INSTALL substrait"); dbExecute(con, "LOAD substrait"); duckdb_get_substrait(con, sql): Returns Substrait BLOB. duckdb_get_substrait_json(con, sql): Returns JSON. duckdb_prepare_substrait(con, blob): Prepares BLOB. dbFetch(result): Executes prepared statement. TPC-DS Extension: Data generator and queries. Usage: `INSTALL tpcds; LOAD tpcds;`: install/load. `CALL dsdgen(sf=scale_factor)`: generate data. `PRAGMA tpcds(query_id)`: run query. Limitations: fixed parameters. TPC-H Extension: Data generator and queries for TPC-H benchmark. INSTALL tpch; LOAD tpch; CALL dbgen(sf = DOUBLE); Generate data for scale factor sf. Parameters: catalog VARCHAR, children UINTEGER, overwrite BOOLEAN, sf DOUBLE, step UINTEGER, suffix VARCHAR. FROM tpch_queries(); Returns table(query_nr, query). Lists all 22 queries. FROM tpch_answers(); Returns table(query_nr, scale_factor, answer). Lists expected answers. PRAGMA tpch(query_nr); Runs query number query_nr. Extension Versioning: Unstable (git hash), Pre-Release (v0.y.z, SemVer), Stable (vx.y.z, SemVer). Release cycle depends on stability. Nightly builds available. Update extensions: UPDATE EXTENSIONS. Extensions are tied to a specific DuckDB version. Vector Similarity Search Extension. CREATE INDEX index_name ON table_name USING HNSW (column) [WITH (metric='l2sq'/'cosine'/'ip', ef_construction=int, ef_search=int, M=int, M0=int)]. Distance metrics: l2sq (array_distance), cosine (array_cosine_distance), ip (array_negative_inner_product). Index options: metric, ef_construction, ef_search, M, M0, hnsw_ef_search (SET hnsw_ef_search=int/RESET hnsw_ef_search). Usage: ORDER BY array_distance(vec, constant_vector) LIMIT n; min_by(table, array_distance(vec, constant_vector), n). EXPLAIN output shows HNSW_INDEX_SCAN. Persistence: experimental, SET hnsw_enable_experimental_persistence=bool. Re-compaction: PRAGMA hnsw_compact_index('index_name'). Vector Similarity Search Joins: vss_join(left_table, right_table, left_col, right_col, k, metric), vss_match(right_table, left_col, right_col, k, metric). Limitations: FLOAT vectors only, index in RAM (not memory_limit), persistence experimental, vector join macros no index usage. Working with Extensions. Platforms: linux_amd64, linux_arm64, osx_amd64, osx_arm64, windows_amd64. Shared installation across clients of same DuckDB version/platform. Extension Repositories: core (default), core_nightly, community, local_build_debug, local_build_release. INSTALL extension [FROM repository_alias/'repository_url']. FORCE INSTALL to re-download. Custom repository structure: base_url/v{version}/{platform}/{extension}.duckdb_extension[.gz]. Direct S3 download URL: http://extensions.duckdb.org/v{version}/{platform}/{extension}.duckdb_extension.gz. INSTALL/LOAD 'path/to/extension'. Limitations: cannot reinstall/unload. DuckDB Doc: Topics: Connecting (Overview, APIs, CLI, Java, Python, R, Wasm), SQL (Intro, Statements, Guides), Install. Updated: 2024-11-23. Offline doc. DuckDB Internals: Parser: SQLString -> tokens. Binder: Resolves tables, columns, types. Logical Planner: Creates LogicalOperator nodes. Optimizer: Optimizes query plans (expression rewriting, filter pushdown, join order, common subexpressions, IN clause). Physical Plan Generator: Logical -> PhysicalOperator. Execution: Push-based, vectorized. DataChunks are pushed through the operator tree. PIVOT: Implemented using SQL re-writing and PhysicalPivot operator. Aggregates into lists then converts to columns. Dynamic columns detected using ENUM types. UNPIVOT: Implemented using SQL re-writes with unnest functions. Dynamic column list calculation supported. Storage versions, format compatibility. Backward compatibility from v0.10. Forward compatibility best effort. Move formats: EXPORT DATABASE 'tmp', IMPORT DATABASE 'tmp'. Storage header, version table. Compression algorithms: Constant, RLE, Bit Packing, FOR, Dictionary, FSST, ALP, Chimp. Row groups. Incompatible DB error: update DuckDB or EXPORT/IMPORT. Vector: in-memory data container DataChunk vector collection. Vectorized execution STANDARD_VECTOR_SIZE=2048. Vector formats: Flat Constant Dictionary Sequence UnifiedVectorFormat. Complex types: String string_t inlined pointer List list_entry_t child Vector Struct Map LIST[STRUCT] Union STRUCT tag Vector. Sitemap Constraints: Enforce data properties. Impact performance. CHECK (expression): Arbitrary Boolean expression check. CREATE TABLE students (name VARCHAR CHECK (NOT contains(name, ' '))); NOT NULL: Column cannot contain NULL. CREATE TABLE students (name VARCHAR NOT NULL); PRIMARY KEY, UNIQUE: Unique identifier for a row. ART index created. CREATE TABLE students (id INTEGER PRIMARY KEY, name VARCHAR); FOREIGN KEY: Refers to primary key/unique constraint in another table. ART index created. CREATE TABLE exams (exam_id INTEGER REFERENCES students(id), grade INTEGER); Array Type: Stores fixed-size arrays of same type/length. Use LIST for variable-length. Creating Arrays: array_value(expr, ...). Implicit cast to LIST. SELECT array_value(1, 2, 3); Defining an Array Field: CREATE TABLE t (arr INTEGER[3]); Retrieving Values: arr[i], list_extract(arr, i), array_extract(arr, i). Slicing: arr[i:j] returns LIST. Functions: LIST functions work on ARRAY. array_cross_product(x, y), array_cosine_similarity(x, y). Ordering: Lexicographical. NULL > all values. BITSTRING: variable-length strings of 1s and 0s. SELECT '101010'::BITSTRING AS b; SELECT bitstring('0101011', 12) AS b; Blob Type. Aliases: BYTEA, BINARY, VARBINARY. Description: variable-length binary data. Usage: store binary objects, images. Example: SELECT '\\xAA'::BLOB; SELECT 'AB'::BLOB;. Max size: 4GB. For large files, store path in VARCHAR instead. See Blob Functions. Boolean Type represents true/false logical values. Aliases: BOOL, BOOLEAN. Possible values: true, false, NULL (unknown). Literals: true, false. Used in WHERE and HAVING clauses for filtering. Conjunctions: AND, OR. Expressions: Logical Operators, Comparison Operators. DATE: calendar date (YYYY-MM-DD). Special values: epoch, infinity, -infinity. SELECT DATE '1992-09-20'; Enum: dictionary encoding low cardinality strings. Create: CREATE TYPE AS ENUM ([values]) CREATE TYPE AS ENUM (SELECT ...). Usage: CREATE TABLE. Casts to VARCHAR. Comparison ordering by definition. DROP TYPE warning behavior change. See Enum Functions. INTERVAL represents a period of time. Supported units: YEAR, MONTH, DAY, MICROSECOND. Arithmetic with DATE, TIMESTAMP, TIMESTAMPTZ, TIME. Comparisons with =, <, >. datepart() for extracting components (year, month, day, hour, minute, microsecond, decade, quarter, second, millisecond). LIST type: lists of same type values like PostgreSQL ARRAY. Create: list_value() []. Retrieve: [] slice list_extract() array_slice(). Comparison operators ordering positional. Update: insert delete may cause primary key errors. See List Functions. Literal Types: Special literal types for NULL, integer, string. NULL: Keyword NULL. Can be implicitly converted to any other type. Integer Literals: Sequence of digits. INTEGER_LITERAL type. Implicitly converted to integer type if value fits. Non-integer Numeric Literals: Decimal notation using (.). E notation: e/E followed by integer exponent. Underscores in Numeric Literals: Allowed as separators. String Literals: Delimited by single quotes ('). Double quotes delimit quoted identifiers. Implicit String Literal Concatenation: Consecutive single-quoted strings separated by whitespace with newline. STRING_LITERAL: Can be implicitly converted to any other type. Escape String Literals: '' to escape a single quote. E'...' or e'...' for special characters. Escape sequences: \\b, \\f, \\n, \\r, \\t. Dollar-Quoted String Literals: Surrounded by $$. SELECT $$Hello world$$ AS msg; MAP: Ordered list of entries (key-value). Keys must be unique. MAP {'key': value,...} or map_from_entries([('key', value),...]) or MAP([keys], [values]). MAPs use bracket notation for retrieval: MAP['key']. Returns empty list if key not found. element_at(map, key). NULL values: Represent missing data. Comparisons with NULL return NULL. Use IS (NOT) NULL to check for NULL. IS NOT DISTINCT FROM: equality comparison where NULL values compare equal. coalesce(arg1, arg2, ...) -> value: Returns the first non-NULL argument. ifnull(arg1, arg2) -> value: Two-argument version of coalesce. Aggregate functions: ignore NULLs, except first, last, list, array_agg. Use FILTER to exclude NULLs from the exceptions. Numeric Types: Integer Types: TINYINT, SMALLINT, INTEGER, BIGINT, HUGEINT (signed). UTINYINT, USMALLINT, UINTEGER, UBIGINT, UHUGEINT (unsigned). Name Min Max TINYINT -128 127 SMALLINT -32768 32767 INTEGER -2147483648 2147483647 BIGINT -9223372036854775808 9223372036854775807 HUGEINT -1701411834604692317... 1701411834604692317... Fixed-Point Decimals: DECIMAL(WIDTH, SCALE) / NUMERIC(WIDTH, SCALE). Default: DECIMAL(18, 3). WIDTH: Total digits. SCALE: Digits after decimal. Internal size: INT16 (1-4), INT32 (5-9), INT64 (10-18), INT128 (19-38). INT128 is slower. Floating-Point Types: FLOAT (single), DOUBLE (double). IEEE 754. Name Description FLOAT single precision (4 bytes) DOUBLE double precision (8 bytes) Special Values: Infinity, -Infinity, NaN (case-insensitive strings). UUIDs: Universally Unique Identifiers. 128 bits. HUGEINT internally. Format: 8-4-4-4-12 (hexadecimal). uuid(): Generates new UUID. Data types: BIGINT, BIT, BLOB, BOOLEAN, DATE, DECIMAL(prec, scale), DOUBLE, FLOAT, HUGEINT, INTEGER, INTERVAL, JSON, SMALLINT, TIME, TIMESTAMP WITH TIME ZONE, TIMESTAMP, TINYINT, UBIGINT, UHUGEINT, UINTEGER, USMALLINT, UTINYINT, UUID, VARCHAR. Nested types: ARRAY, LIST, MAP, STRUCT, UNION. ARRAY: fixed-length same type. LIST: variable-length same type. MAP: dict same key/value type. STRUCT: dict string keys varied value types. UNION: alternative types. Nested update: delete+insert, ART index constraint errors. Data type choice affects performance. STRUCT Data Type: Ordered list of columns (entries), referenced by name (keys). Same keys for each row. Fixed schema. Similar to PostgreSQL ROW type. Creating Structs: struct_pack(name := expr,...), {'name': expr,...}, row function. Accessing: dot notation, bracket notation, struct_extract(struct, key). STRUCT.* retrieves all keys as separate columns. Dot Notation precedence: columns, then struct keys. Comparison: Uses PostgreSQL semantics, matching keys must be at identical positions. Equality if all values equal. Less Than, first index where values differ determines result. NULL values follow PG semantics. Example: SELECT struct_pack(key1 := 'value1', key2 := 42) AS s; SELECT a.x FROM (SELECT {'x': 1, 'y': 2, 'z': 3} AS a); VARCHAR, STRING, TEXT: variable-length character strings (Unicode, UTF-8). VARCHAR(n) - max length (ignored). Use CHECK constraint for length restriction. String literals: escape or dollar-quoted. Example: SELECT 'Hello' || chr(10) || 'world' AS msg; TIME: time of day. TIMETZ: time of day with timezone. Instances: TIME 'hh:mm:ss[.zzzzzz]', TIMETZ 'hh:mm:ss[.zzzzzz][+-TT[:tt]]'. TIMESTAMP, TIMESTAMPTZ: represent points in time. TIMESTAMP_NS, TIMESTAMP, TIMESTAMP_MS, TIMESTAMP_S: aliases with different precisions. Use ISO 8601 format. Special values: epoch, infinity, -infinity. Time Zone List: pg_timezone_names() table func for names, abbreviations. Typecasting: Converts value to another data type. Explicit: CAST(col AS VARCHAR) or col::VARCHAR. Implicit: automatic conversions. Lossy casts allowed. Overflows throw errors. TRY_CAST returns NULL on error. VARCHAR: universal target. Lists/Arrays: cast applied to children. Structs: fields reshuffled based on names. Unions: see UNION type page. UNION types hold one of multiple alternative values. union_value(tag := expr) creates UNION values. Casting to UNION: a type can be implicitly cast to a UNION if it can be implicitly cast to one of the UNION member types. Casting between Unions: source type is a subset of the target type. union_extract(u, 'str') extracts a member. u.str can be used. union_tag(u) returns active tag. CREATE OR REPLACE TABLE. CREATE TABLE ... AS SELECT. INSERT INTO ... BY NAME. INSERT OR IGNORE INTO ... INSERT OR REPLACE INTO ... DESCRIBE. SUMMARIZE. FROM-first syntax. GROUP BY ALL. ORDER BY ALL. SELECT * EXCLUDE/REPLACE. UNION BY NAME. PIVOT/UNPIVOT. SET VARIABLE/RESET VARIABLE. max(arg, n), min(arg, n), arg_max(arg, val, n), arg_min(arg, val, n), max_by(arg, val, n) and min_by(arg, val, n). Indexing: 1-based indexing, except for JSON objects (0-based). Example: list[1], json[1]. SQL Identifiers: Unquoted: no keywords, no leading numbers/special chars/whitespace. Quoted: any chars, escape "" with """". Deduplication: name_count for conflicts. Case-insensitive, preserve_identifier_case config. Order Preservation: DuckDB preserves insertion order. Operations: CSV reader. Configuration: preserve_insertion_order (default true). SET preserve_insertion_order = false. DuckDB SQL dialect based on PostgreSQL. Matches PostgreSQL semantics, but may differ in some use cases (e.g., order preservation of inserts). DuckDB's SQL dialect follows PostgreSQL. Differences: Floating-point arithmetic (IEEE 754). Integer division uses float division. Boolean/Integer UNION: DuckDB casts, PostgreSQL errors. Case sensitivity for quoted identifiers (DuckDB is case-insensitive). Double equality (==) supported. VACUUM only rebuilds statistics. to_date not supported. Type name resolution in CREATE TABLE. CASE Statement: CASE WHEN cond THEN a ELSE b END equivalent to IF(cond, a, b). WHEN cond THEN expr can be chained. ELSE is optional, returns NULL if no match. CASE expr WHEN val THEN result [WHEN ...] [ELSE result] END. Example: SELECT i, CASE WHEN i > 2 THEN 1 ELSE 0 END AS test FROM integers; SELECT i, CASE i WHEN 1 THEN 10 WHEN 2 THEN 20 ELSE 0 END AS test FROM integers; SQL CAST(expr AS TYPENAME) or expr::TYPENAME: Explicit type conversion. Errors if invalid cast. TRY_CAST(expr AS TYPENAME): Returns NULL on failure. Collations define text sorting/comparison rules. BINARY is default collation. NOCASE, NOACCENT, NFC are included. Can combine collations using the dot operator. Default collator can be specified globally (PRAGMA default_collation) or per-column. ICU collations are region-dependent, use the ICU extension. Comparison Operators: <, >, <=, >=, =, <>, !=. NULL comparison result is NULL. Distinction operators: IS DISTINCT FROM, IS NOT DISTINCT FROM (NULL safe). BETWEEN: a BETWEEN x AND y (x <= a AND a <= y). NOT BETWEEN: a NOT BETWEEN x AND y (x > a OR a > y). IS NULL/ISNULL: expression IS NULL. IS NOT NULL/NOTNULL: expression IS NOT NULL. BETWEEN x AND y: if x > y, result is false. IN Operator: Checks containment of left expression in right-hand side set. Returns true if present, false if not and no NULLs, NULL if not and NULLs present. SELECT 'Math' IN ('CS', 'Math'); -- true NOT IN: Checks if element is not present. x NOT IN y is equivalent to NOT (x IN y). Use with Subqueries: IN operator with subquery returning a single column. Logical operators: AND, OR, NOT. NULL AND false evaluates to false, NULL OR true evaluates to true. NOT NULL evaluates to NULL. Expressions combine values, operators, and functions. They are highly composable. * (Star Expression): Selects all columns from FROM clause. SELECT * FROM table_name; count(*): Counts rows. SELECT count(*) FROM table_name; Shorthand: SELECT count() FROM table_name; table_name.*: Selects all columns from table. SELECT table_name.* FROM table_name JOIN other_table_name USING (id); EXCLUDE (column): Excludes columns. SELECT * EXCLUDE (city) FROM addresses; REPLACE (expr AS column): Replaces column values. SELECT * REPLACE (lower(city) AS city) FROM addresses; COLUMNS(lambda/regex/list): Applies expression to columns. SELECT COLUMNS(c -> c LIKE '%num%') FROM addresses; SELECT COLUMNS('number\d+') FROM addresses; SELECT COLUMNS(['city', 'zip_code']) FROM addresses; *COLUMNS: Unpacks columns in-place. SELECT coalesce(*COLUMNS(['a', 'b', 'c'])) AS result FROM (SELECT NULL AS a, 42 AS b, true AS c); STRUCT.*: Retrieves all keys from struct as separate columns. SELECT st.* FROM (SELECT {'x': 1, 'y': 2, 'z': 3} AS st); COLUMNS in WHERE: Conditions applied to all columns with AND. Renaming Columns: SELECT COLUMNS('(\\w{3}).*') AS '\\1' FROM numbers; (Capture groups are one-indexed) Subqueries: Parenthesized query expressions. Scalar subquery: Returns a single value. ALL, ANY, SOME: Quantifiers for subquery comparisons. EXISTS: Tests for row existence in subquery. NOT EXISTS: Tests for absence of rows in subquery. IN operator: Checks containment. Correlated subquery: Subquery uses values from the parent query. Subquery in SELECT clause: Returns struct for each row. Aggregate Functions: combine multiple rows into a single value. Used in SELECT and HAVING clauses. DISTINCT: considers distinct values. ORDER BY: sorts values before aggregation (for order-sensitive functions). General Aggregates: any_value(arg), arbitrary(arg), arg_max(arg, val[,n]), arg_max_null(arg, val), arg_min(arg, val[,n]), arg_min_null(arg, val), array_agg(arg), avg(arg), bit_and(arg), bit_or(arg), bit_xor(arg), bitstring_agg(arg), bool_and(arg), bool_or(arg), count([arg]), favg(arg), first(arg), fsum(arg), geomean(arg), histogram(arg), last(arg), list(arg), max(arg[,n]), max_by(arg, val[,n]), min(arg[,n]), min_by(arg, val[,n]), product(arg), string_agg(arg, sep), sum(arg). Approximate Aggregates: approx_count_distinct(x), approx_quantile(x, pos), reservoir_quantile(x, quantile, sample_size). Statistical Aggregates: corr(y, x), covar_pop(y, x), covar_samp(y, x), entropy(x), kurtosis_pop(x), kurtosis(x), mad(x), median(x), mode(x), quantile_cont(x, pos), quantile_disc(x, pos), regr_avgx(y, x), regr_avgy(y, x), regr_count(y, x), regr_intercept(y, x), regr_r2(y, x), regr_slope(y, x), regr_sxx(y, x), regr_sxy(y, x), regr_syy(y, x), skewness(x), stddev_pop(x), stddev_samp(x), var_pop(x), var_samp(x). Ordered Set Aggregates: mode() WITHIN GROUP (ORDER BY), percentile_cont() WITHIN GROUP (ORDER BY), percentile_disc() WITHIN GROUP (ORDER BY). Miscellaneous Aggregate Functions: grouping(), grouping_id(). Functions: array_value(), array_cross_product(), array_cosine_similarity(), array_cosine_distance(), array_distance(), array_inner_product(), array_negative_inner_product(), array_dot_product(), array_negative_dot_product(). Bitstring Functions: Operators: &, |, xor, ~, <<, >>. Functions: bit_count(bitstring): Count set bits; returns INTEGER. bit_length(bitstring): Number of bits; returns INTEGER. bit_position(substring, bitstring): Index of substring; returns INTEGER. bitstring(bitstring, length): Bitstring of length; returns BITSTRING. get_bit(bitstring, index): Extract bit at index; returns INTEGER. length(bitstring): Alias for bit_length. octet_length(bitstring): Bytes in bitstring; returns INTEGER. set_bit(bitstring, index, new_value): Set bit; returns BITSTRING. Aggregate Functions: bit_and(arg), bit_or(arg), bit_xor(arg), bitstring_agg(arg), bitstring_agg(arg, min, max). Blob Functions: blob || blob: BLOB concatenation; returns BLOB. decode(blob): Convert blob to VARCHAR; returns VARCHAR, fails on invalid UTF-8. encode(string): Convert string to BLOB; returns BLOB. hex(blob): Convert blob to VARCHAR (hex); returns VARCHAR. octet_length(blob): Number of bytes in blob; returns INTEGER. read_blob(source): Return content from source (file/glob) as BLOB; returns BLOB. Example: read_blob('hello.bin'). string ^@ search_string: Returns true if string begins with search_string. string || string: Concatenates two strings, NULL input results in NULL. string[index]: Extracts a single character (1-based index). string[begin:end]: Extracts a substring using slice conventions. string LIKE target: Returns true if the string matches the like specifier. string SIMILAR TO regex: Returns true if the string matches the regex. array_extract(list, index): Extracts a single character (1-based index). array_slice(list, begin, end): Extracts a substring. ascii(string): Returns the Unicode code point of the first character. bar(x, min, max[, width]): Draws a band proportional to (x - min). bit_length(string): Number of bits in a string. chr(x): Returns a character corresponding to an ASCII or Unicode code point. concat_ws(separator, string, ...): Concatenates strings with a separator, skipping NULLs. concat(string, ...): Concatenates strings, skipping NULLs. contains(string, search_string): Returns true if search_string is found. ends_with(string, search_string): Returns true if string ends with search_string. format_bytes(bytes): Converts bytes to human-readable format (KiB, MiB, etc.). format(format, parameters, ...): Formats a string using the fmt syntax. from_base64(string): Converts a base64 encoded string. greatest(x1, x2, ...): Selects the largest value (lexicographical ordering). hash(value): Returns the hash of the value as UBIGINT. ilike_escape(string, like_specifier, escape_character): Case-insensitive LIKE. instr(string, search_string): Returns the starting position of search_string (1-based). Returns 0 if no match. least(x1, x2, ...): Selects the smallest value (lexicographical ordering). left_grapheme(string, count): Extracts the left-most grapheme clusters. left(string, count): Extracts the left-most count characters. length_grapheme(string): Number of grapheme clusters in string. length(string): Number of characters in string. like_escape(string, like_specifier, escape_character): Case-sensitive LIKE. lower(string): Converts string to lower case. lpad(string, count, character): Pads the string from the left. ltrim(string, characters): Removes characters from the left side. ltrim(string): Removes spaces from the left side. md5(string): Returns the MD5 hash as VARCHAR. md5_number(string): Returns the MD5 hash as HUGEINT. md5_number_lower(string): Returns the lower 64-bit segment of the MD5 hash as BIGINT. md5_number_higher(string): Returns the higher 64-bit segment of the MD5 hash as BIGINT. nfc_normalize(string): Converts to Unicode NFC normalized string. not_ilike_escape(string, like_specifier, escape_character): Returns false for case-insensitive LIKE. not_like_escape(string, like_specifier, escape_character): Returns false for case-sensitive LIKE. ord(string): Returns ASCII character code of the leftmost character. parse_dirname(path, separator): Returns the top-level directory name. parse_dirpath(path, separator): Returns the head of the path. parse_filename(path, trim_extension, separator): Returns the last component of the path. parse_path(path, separator): Returns a list of path components. position(search_string IN string): Returns starting position of search_string (1-based). Returns 0 if no match. printf(format, parameters...): Formats a string using printf syntax. read_text(source): Returns the content from source as VARCHAR. regexp_escape(string): Escapes special patterns for regex. regexp_extract(string, pattern[, group = 0]): Extracts a capturing group. regexp_extract(string, pattern, name_list): Extracts capturing groups into a struct. regexp_extract_all(string, regex[, group = 0]): Extracts all occurrences of group. regexp_full_match(string, regex): Returns true if the entire string matches the regex. regexp_matches(string, pattern): Returns true if the string contains the regex. regexp_replace(string, pattern, replacement): Replaces matching parts. regexp_split_to_array(string, regex): Splits the string along the regex. regexp_split_to_table(string, regex): Splits the string along the regex. repeat(string, count): Repeats the string count times. replace(string, source, target): Replaces occurrences of source. reverse(string): Reverses the string. right_grapheme(string, count): Extracts the right-most grapheme clusters. right(string, count): Extracts the right-most count characters. rpad(string, count, character): Pads the string from the right. rtrim(string, characters): Removes characters from the right side. rtrim(string): Removes spaces from the right side. sha256(value): Returns the SHA-256 hash as VARCHAR. split_part(string, separator, index): Splits and returns the part at the index (1-based). Returns "" if index out of bounds. starts_with(string, search_string): Returns true if string starts with search_string. str_split_regex(string, regex): Splits the string along the regex. string_split_regex(string, regex): Splits the string along the regex. string_split(string, separator): Splits the string along the separator. strip_accents(string): Strips accents from string. strlen(string): Number of bytes in string. strpos(string, search_string): Returns the starting position of search_string (1-based). Returns 0 if no match. substring(string, start, length): Extracts a substring. substring_grapheme(string, start, length): Extracts a substring of grapheme clusters. to_base64(blob): Converts a blob to base64. trim(string, characters): Removes characters from both sides. trim(string): Removes spaces from both sides. unicode(string): Returns the Unicode code of the first character. Returns -1 if empty, NULL if NULL. upper(string): Converts string to upper case. damerau_levenshtein(s1, s2): Calculates the Damerau-Levenshtein distance. editdist3(s1, s2): Alias of levenshtein. hamming(s1, s2): Calculates the Hamming distance. Strings must be of equal length. jaccard(s1, s2): Calculates the Jaccard similarity (0 to 1). jaro_similarity(s1, s2): Calculates the Jaro similarity (0 to 1). jaro_winkler_similarity(s1, s2): Calculates the Jaro-Winkler similarity (0 to 1). levenshtein(s1, s2): Calculates the Levenshtein distance. mismatches(s1, s2): Alias for hamming. Date Operators: + (add days, INTERVAL), - (subtract DATEs, INTERVAL) Date Functions: current_date, date_add(date, interval), date_diff(part, startdate, enddate), date_part(part, date), date_sub(part, startdate, enddate), date_trunc(part, date), datediff(part, startdate, enddate), datepart(part, date), datesub(part, startdate, enddate), datetrunc(part, date), dayname(date), extract(part from date), greatest(date, date), isfinite(date), isinf(date), last_day(date), least(date, date), make_date(year, month, day), monthname(date), strftime(date, format), time_bucket(bucket_width, date[, offset]), time_bucket(bucket_width, date[, origin]), today() Return types and examples are in raw doc. Date Part Extraction Functions: Extract subfields from dates (day, weekday, etc.). Infinite dates return same or NULL. Date Format Functions: Convert between DATE/TIMESTAMP and strings. strftime(timestamp, format): Converts timestamps/dates to strings. strptime(text, format): Converts strings to timestamps. Throws error on failure. try_strptime(text, format): Converts strings to timestamps. Returns NULL on failure. COPY dates FROM 'test.csv' (DATEFORMAT '%d/%m/%Y', TIMESTAMPFORMAT '%A, %-d %B %Y - %I:%M:%S %p'); SELECT * FROM read_csv('test.csv', dateformat = '%m/%d/%Y'); Specifiers: %a, %A, %b, %B, %c, %d, %-d, %f, %g, %G, %H, %-H, %I, %-I, %j, %-j, %m, %-m, %M, %-M, %n, %p, %S, %-S, %u, %U, %V, %w, %W, %x, %X, %y, %-y, %Y, %z, %Z, %%. Date Part Functions: manipulate temporal type fields. Specifiers: 'century', 'day', 'decade', 'hour', 'microseconds', 'millennium', 'milliseconds', 'minute', 'month', 'quarter', 'second', 'year', 'dayofweek', 'dayofyear', 'epoch', 'era', 'isodow', 'isoyear', 'timezone_hour', 'timezone_minute', 'timezone', 'week', 'yearweek'. Functions: century(date), day(date), dayofmonth(date), dayofweek(date), dayofyear(date), decade(date), epoch(date), era(date), hour(date), isodow(date), isoyear(date), microsecond(date), millennium(date), millisecond(date), minute(date), month(date), quarter(date), second(date), timezone_hour(date), timezone_minute(date), timezone(date), week(date), weekday(date), weekofyear(date), year(date), yearweek(date). Each function extracts the corresponding part from the date. Enum Functions: Functions for examining and manipulating ENUM values. enum_code(enum_value): Returns the numeric value of enum_value. Example: enum_code('happy'::mood) Result: 2 enum_first(enum): Returns the first value of the enum type. Example: enum_first(NULL::mood) Result: sad enum_last(enum): Returns the last value of the enum type. Example: enum_last(NULL::mood) Result: anxious enum_range(enum): Returns all values of the enum type as an array. Example: enum_range(NULL::mood) Result: [sad, ok, happy, anxious] enum_range_boundary(enum, enum): Returns the range between two enum values as an array. First/second parameter NULL: start/end of enum type. Example: enum_range_boundary(NULL, 'happy'::mood) Result: [sad, ok, happy] Interval operators: +, -, date/timestamp/time +/ - interval. Functions: date_part(part, interval), datepart(part, interval), extract(part FROM interval) - extract components. epoch(interval) - seconds. to_centuries(integer), to_days(integer), to_decades(integer), to_hours(integer), to_microseconds(integer), to_millennia(integer), to_milliseconds(integer), to_minutes(integer), to_months(integer), to_seconds(integer), to_weeks(integer), to_years(integer) - construct interval. Lambda Functions: (param1, param2, ...) -> expression or param -> expression. list_transform(list, lambda): apply lambda to each element. Aliases: array_transform, apply, list_apply, array_apply. Example: list_transform([1], x -> x + 1). list_filter(list, lambda): filter list by lambda (true keeps). Aliases: array_filter, filter. Example: list_filter([4, 5], x -> x > 4). list_reduce(list, lambda): reduce list to single value. Aliases: array_reduce, reduce. Example: list_reduce([4, 5], (x, y) -> x + y). Nesting supported. Scoping: inner lambda -> outer lambda -> columns -> macros. Optional index param (1-based) in lambda: (x, i) -> expression. List Functions: list[index]: Alias for list_extract. list[begin:end]: Alias for list_slice. list[begin:end:step]: list_slice with step. array_pop_back(list): Returns list without last element. array_pop_front(list): Returns list without first element. flatten(list_of_lists): Concatenates list of lists. len(list): Returns list length. list_aggregate(list, name): Executes aggregate function on list elements. list_any_value(list): Returns first non-null value. list_append(list, element): Appends element to list. list_concat(list1, list2): Concatenates two lists. list_contains(list, element): Returns true if list contains element. list_cosine_similarity(list1, list2): Cosine similarity between lists. list_cosine_distance(list1, list2): Cosine distance. list_distance(list1, list2): Euclidean distance. list_distinct(list): Removes duplicates and NULLs. list_dot_product(list1, list2): Dot product. list_negative_dot_product(list1, list2): Negative dot product. list_extract(list, index): Extracts element at index (1-based). list_filter(list, lambda): Filters list based on lambda. list_grade_up(list): Returns sort indexes. list_has_all(list, sub-list): True if list contains all sub-list elements. list_has_any(list1, list2): True if lists share any elements. list_intersect(list1, list2): Returns common elements. list_position(list, element): Returns element index or NULL. list_prepend(element, list): Prepends element. list_reduce(list, lambda): Reduces list to single value using lambda. list_resize(list, size[, value]): Resizes list; pads with value or NULL. list_reverse_sort(list): Sorts list in reverse order. list_reverse(list): Reverses list. list_select(value_list, index_list): Selects elements by index. list_slice(list, begin, end, step): Extracts sublist with step. list_slice(list, begin, end): Extracts sublist. list_sort(list): Sorts list. list_transform(list, lambda): Transforms list using lambda. list_unique(list): Counts unique elements. list_value(any, ...): Creates a LIST. list_where(value_list, mask_list): Filters list with boolean mask. list_zip(list_1, list_2, ...[, truncate]): Zips lists into list of tuples, truncates if truncate is set. unnest(list): Unnests list by one level. Operators: &&: list_has_any. @>: list_has_all (right is sublist). <@: list_has_all (left is sublist). ||: list_concat. <=>: list_cosine_distance. <->: list_distance. Range Functions: range(start, stop, step): Creates list from start (inclusive) to stop (exclusive). Defaults: start=0, step=1. generate_series(start, stop, step): Creates list from start (inclusive) to stop (inclusive). Date ranges supported for TIMESTAMP. Slicing: list_slice(list, begin, end[, step]). Bracket notation supported. List Aggregates: list_aggregate(list, aggregate_function_name, ...). list_min, list_max, list_sum, etc. array_to_string(list, delimiter): Concatenates list elements with delimiter. Sorting: list_sort(list, ['ASC'|'DESC'], ['NULLS FIRST'|'NULLS LAST']). Default: ASC NULLS FIRST. Flattening: flatten(list_of_lists): Converts list of lists to single list. Lambda Functions: (param1, param2, ...) -> expression. Related: list, histogram, unnest. Map Functions: cardinality(map): Returns map size. element_at(map, key): Returns value for key or empty list. map_contains(map, key): Checks if map contains key. map_contains_entry(map, key, value): Checks if map contains key-value pair. map_contains_value(map, value): Checks if map contains value. map_entries(map): Returns list of struct(k, v) for each key-value pair. map_extract(map, key): Alias of element_at. map_from_entries(STRUCT(k, v)[]): Returns map from array entries. map_keys(map): Returns list of all keys. map_values(map): Returns list of all values. map(): Returns empty map. map[entry]: Alias for element_at. Nested Functions: ARRAY, LIST, MAP, STRUCT, UNION types and functions. Numeric Operators: +, -, *, /, // (int div), %, **, ^ (exp), &, |, <<, >>, ~, ! (factorial). / is float division, // is integer division for integers. Functions: @(x), abs(x), acos(x), add(x, y), asin(x), atan(x), atan2(y, x), bit_count(x), cbrt(x), ceil(x), ceiling(x), cos(x), cot(x), degrees(x), divide(x, y), even(x), exp(x), factorial(x), fdiv(x, y), floor(x), fmod(x, y), gamma(x), gcd(x, y), greatest_common_divisor(x, y), greatest(x1, x2, ...), isfinite(x), isinf(x), isnan(x), lcm(x, y), least_common_multiple(x, y), least(x1, x2, ...), lgamma(x), ln(x), log(x), log10(x), log2(x), multiply(x, y), nextafter(x, y), pi(), pow(x, y), power(x, y), radians(x), random(), round_even(v NUMERIC, s INTEGER), round(v NUMERIC, s INTEGER), setseed(x), sign(x), signbit(x), sin(x), sqrt(x), subtract(x, y), tan(x), trunc(x), xor(x, y). Example: abs(-17.4) Functions: Function chaining: arg1.fn(arg2, arg3, ...). duckdb_functions() table function lists built-in functions. Examples: base64, bin, bit_count, bit_length, bit_position, bitstring. Pattern Matching: LIKE, SIMILAR TO, GLOB, Regular Expressions. LIKE: Returns true if string matches pattern. _ matches any single character, % matches zero or more characters. ILIKE: Case-insensitive LIKE. LIKE ESCAPE: Use ESCAPE clause for literal wildcard characters. SIMILAR TO: Uses regular expression. Matches the entire string. GLOB: File name expansion. ? matches any single character, * matches zero or more characters, [...] matches character range. Case-sensitive. GLOB ~~~: Symbolic-style GLOB glob table function: Accepts a path to search (may include glob patterns). glob('*'): Search the current directory for all files. Regular Expressions: Pattern matching operators (LIKE, SIMILAR TO, GLOB), and regex functions. Uses RE2 library. regexp_extract(string, pattern[, group = 0][, options]): Returns capturing group. regexp_extract(string, pattern, name_list[, options]): Returns capturing groups as struct. regexp_extract_all(string, regex[, group = 0][, options]): Extracts all occurrences of group. regexp_full_match(string, regex[, options]): Returns true if entire string matches regex. regexp_matches(string, pattern[, options]): Returns true if string contains regex pattern. regexp_replace(string, pattern, replacement[, options]): Replaces matching part. regexp_split_to_array(string, regex[, options]): Alias of string_split_regex. regexp_split_to_table(string, regex[, options]): Splits and returns a row for each part. Options: 'c', 'i', 'l', 'm', 'n', 'p', 'g', 's'. Limitations: Only supports 9 capture groups: \\1, \\2, \\3, …, \\9. Struct Functions: struct.entry, struct[entry], struct[idx], row(any,...), struct_extract(struct, 'entry'/'idx'), struct_insert(struct, name := any, ...), struct_pack(name := any, ... struct_extract: extracts fields from STRUCTs (1-based index for unnamed). struct_insert: adds fields to STRUCTs. struct_pack: creates STRUCTs. Time Functions: Operators: `+`: add interval, `-`: subtract interval. Functions: `current_time`/`get_current_time()`: current time. `date_diff(part, starttime, endtime)`/`datediff()`: partition boundaries. `date_part(part, time)`/`datepart()`/`extract(part FROM time)`: get subfield. `date_sub(part, starttime, endtime)`/`datesub()`: complete partitions. `make_time(bigint, bigint, double)`: make time. Timestamp Functions: Operators: `+`: add interval, `-`: subtract timestamps/interval. Functions: `age(timestamp, timestamp)/age(timestamp)`: time difference. `century(timestamp)`: century. `current_timestamp`: current timestamp. `date_diff/datediff(part, startdate, enddate)`: partition boundaries. `date_part/datepart/extract(part, timestamp)`: get subfield. `date_part/datepart([part,...], timestamp)`: get subfields struct. `date_sub/datesub(part, startdate, enddate)`: complete partitions. `date_trunc/datetrunc(part, timestamp)`: truncate. `dayname(timestamp)`: weekday name. `epoch_ms(ms)/epoch_ms(timestamp)`: milliseconds since epoch. `epoch_ns(timestamp)`: nanoseconds epoch. `epoch_us(timestamp)`: microseconds epoch. `epoch(timestamp)`: seconds epoch. `greatest/least(timestamp, timestamp)`: later/earlier. `isfinite/isinf(timestamp)`: finite/infinite. `last_day(timestamp)`: last day month. `make_timestamp(bigint, bigint, bigint, bigint, bigint, double)/make_timestamp(microseconds)`: make timestamp. `monthname(timestamp)`: month name. `strftime(timestamp, format)`: to string. `strptime(text, format-list)/strptime(text, format)`: string to timestamp (error). `try_strptime(text, format-list)/try_strptime(text, format)`: string to timestamp (NULL). `time_bucket(bucket_width, timestamp[, offset/origin])`: time bucket. Table Functions: `generate_series/range(timestamp, timestamp, interval)`: timestamp series table. Infinite values: NULL or same infinite. TIMESTAMPTZ: Stores instant, binned/formatted by current timezone. Built-in: current_timestamp, get_current_timestamp, greatest(timestamptz, timestamptz), isfinite, isinf, least(timestamptz, timestamptz), now, transaction_timestamp. ICU extension: Operators (+,-), Functions (age, date_diff, date_part, date_sub, date_trunc, epoch_ms/ns/us, extract, last_day, make_timestamptz, strftime, strptime, time_bucket). Table functions: generate_series, range. Non-Gregorian calendars supported. timezone(text, timestamp/timestamptz). AT TIME ZONE: syntactic sugar for timezone. Union Functions: union.tag (alias for union_extract), union_extract(union, 'tag') - extract value by tag, union_value(tag := any) - create union value with tag, union_tag(union) - get current tag. Utility Functions: alias(column), checkpoint(database), coalesce(expr, ...), constant_or_null(arg1, arg2), count_if(x), current_catalog(), current_schema(), current_schemas(boolean), current_setting('setting'), currval('sequence'), error(message), force_checkpoint(database), gen_random_uuid(), getenv(var), hash(value), icu_sort_key(string, collator), if(a, b, c), ifnull(expr, other), md5(string), md5_number(string), md5_number_lower(string), md5_number_higher(string), nextval('sequence'), nullif(a, b), pg_typeof(expression), query(query_string), query_table(tbl_name, [by_name]), read_blob(source), read_text(source), sha256(value), stats(expression), txid_current(), typeof(expression), uuid(), version(). Table Functions: glob(search_path), repeat_row(varargs, num_rows). Window Functions: use multiple rows for calculation. Blocking operators. Syntax: SELECT window_function() OVER (PARTITION BY ... ORDER BY ...). General functions: cume_dist(), dense_rank(), first_value(expr[ IGNORE NULLS]), lag(expr[, offset[, default]][ IGNORE NULLS]), last_value(expr[ IGNORE NULLS]), lead(expr[, offset[, default]][ IGNORE NULLS]), nth_value(expr, nth[ IGNORE NULLS]), ntile(num_buckets), percent_rank(), rank(), row_number(). Aggregate functions as window functions. Window clauses: WINDOW window_name AS (...). Framing: ROWS BETWEEN, RANGE BETWEEN, EXCLUDE clauses. QUALIFY clause: filter window function results. Indexes: Min-Max, ART (Adaptive Radix Tree), R-tree (spatial). CREATE INDEX/DROP INDEX. ART indexes: in-memory requirement; updates become deletes/inserts; potential unique constraint violations in transactions. SQL Introduction: DuckDB SQL similar to PostgreSQL. RDBMS: relations/tables, rows, columns, schemas, database. CREATE TABLE table_name (col1 TYPE, col2 TYPE); Data Types: VARCHAR, INTEGER, FLOAT, DATE. DROP TABLE table_name. INSERT INTO table_name VALUES (val1, val2); or INSERT INTO table_name (col1, col2) VALUES (val1, val2); COPY table_name FROM 'file.csv'. SELECT select_list FROM table_list WHERE condition ORDER BY columns. SELECT *, expressions, aliases (AS). WHERE clause for filtering. ORDER BY for sorting. DISTINCT for unique rows. Joins: SELECT * FROM table1, table2 WHERE table1.col = table2.col; or INNER JOIN/LEFT OUTER JOIN. Aggregate functions: max(), min(), avg(), sum(), count(). GROUP BY columns HAVING condition. UPDATE table_name SET col = value WHERE condition. DELETE FROM table_name WHERE condition. Warning: DELETE FROM table_name removes all rows. DuckDB Metadata Functions: Table functions prefixed with duckdb_. Example: SELECT * FROM duckdb_settings(); duckdb_columns(): Metadata about columns. Columns: database_name, schema_name, table_name, column_name, data_type. duckdb_constraints(): Metadata about constraints. Columns: database_name, schema_name, table_name, constraint_type, constraint_text. duckdb_databases(): Lists accessible databases. Columns: database_name, path, type. duckdb_dependencies(): Metadata about dependencies. Columns: objid, refobjid, deptype. duckdb_extensions(): Metadata about extensions. Columns: extension_name, loaded, installed, description. duckdb_functions(): Metadata about functions. Columns: database_name, schema_name, function_name, function_type, return_type, parameters. duckdb_indexes(): Metadata about indexes. Columns: database_name, schema_name, index_name, table_name, is_unique. duckdb_keywords(): Metadata about keywords. Columns: keyword_name, keyword_category. duckdb_memory(): Metadata about memory usage. Columns: tag, memory_usage_bytes, temporary_storage_bytes. duckdb_optimizers(): Metadata about optimizers. Columns: name. duckdb_schemas(): Metadata about schemas. Columns: database_name, schema_name, internal. duckdb_secrets(): Metadata about secrets. Columns: name, type, provider. duckdb_sequences(): Metadata about sequences. Columns: database_name, schema_name, sequence_name, start_value, min_value, max_value, increment_by, cycle. duckdb_settings(): Metadata about settings. Columns: name, value, description, input_type. duckdb_tables(): Metadata about tables. Columns: database_name, schema_name, table_name, internal, temporary, has_primary_key, estimated_size, sql. duckdb_temporary_files(): Metadata about temporary files. Columns: path, size. duckdb_types(): Metadata about types. Columns: database_name, schema_name, type_name, logical_type, type_category, internal. duckdb_variables(): Metadata about variables. Columns: name, value, type. duckdb_views(): Metadata about views. Columns: database_name, schema_name, view_name, internal, temporary, sql. Information Schema: SQL-standard views describing catalog entries. Views: character_sets, columns, constraint_column_usage, key_column_usage, referential_constraints, schemata, tables, table_constraints. Functions: current_catalog() string: Returns current catalog name. current_schema() string: Returns current schema name. current_schemas(boolean) list[string]: Returns schema list. Pass true for implicit schemas. FILTER Clause: Filters rows for aggregate functions in SELECT. Syntax: aggregate_function(...) FILTER (condition). Not for windowing functions. Use for multiple filtered aggregates or pivoting data. Example: SELECT count(*) FILTER (i <= 5). FROM clause: Specifies the data source for a query. Can contain tables, JOIN clauses, or subqueries. FROM-first syntax supported. Examples: SELECT * FROM table_name; FROM table_name SELECT *; Joins: Combine tables horizontally. Types: INNER, LEFT, RIGHT, FULL, CROSS. Conditional joins use ON or WHERE. Natural joins use shared attribute names. Semi/Anti joins return rows with/without matches. Lateral joins allow subqueries to refer to previous subqueries. Positional joins connect tables based on physical order. ASOF joins find nearest event in a reference table using inequality conditions. Self-joins are allowed with aliases. FROM-First Syntax: FROM tbl SELECT i, s; or FROM tbl; GROUP BY clause: Specifies grouping columns for aggregations. SELECT col1, count(*) FROM table GROUP BY col1; GROUP BY ALL: Groups by all non-aggregated columns in SELECT. SELECT city, street_name FROM addresses GROUP BY ALL; GROUPING SETS, CUBE, ROLLUP: Group along multiple dimensions. GROUPING SETS: Aggregate over multiple dimensions. CUBE, ROLLUP for grouping. GROUPING_ID(col1, col2, ...) Returns BIGINT identifying grouping set (0 for regular rows). ROLLUP(col1, col2) generates (col1, col2), (col1), (). CUBE(col1, col2) generates (col1, col2), (col1), (col2), (). HAVING: Filters GROUP BY results. Syntax similar to WHERE but applied after grouping. Example: SELECT city, count(*) FROM addresses GROUP BY city HAVING count(*) >= 50; LIMIT restricts rows fetched. OFFSET starts reading at a position. SELECT * FROM addresses LIMIT 5; SELECT * FROM addresses LIMIT 5 OFFSET 5; ORDER BY for deterministic results. ORDER BY: Sorts rows. ORDER BY expr [ASC|DESC] [NULLS FIRST|NULLS LAST]. ALL keyword sorts by all columns from left to right. SET default_null_order = 'NULLS_FIRST'; SET default_order = 'DESC'; Collations sort text, binary comparison by default. Example: SELECT * FROM addresses ORDER BY city DESC NULLS LAST; Prepared statements support parameters: ?, $1, or $param. PREPARE query_name AS query_text. EXECUTE query_name(params). DEALLOCATE query_name. Example: PREPARE q AS SELECT * FROM person WHERE name = $1; EXECUTE q('Alice'); QUALIFY filters WINDOW function results. SELECT ... QUALIFY ...; Similar to HAVING, avoids subquery or WITH clause. SAMPLE clause: Runs query on a sample of the base table. Syntax: FROM table USING SAMPLE percentage% or number ROWS (sampling_method). SELECT Clause: Specifies columns to return. SELECT * FROM table_name; // Select all columns. SELECT col1 + col2 AS res, sqrt(col1) AS root FROM table_name; // Arithmetic, aliases. SELECT DISTINCT city FROM addresses; // Unique rows. SELECT count(*) FROM addresses; // Row count. SELECT * EXCLUDE (city) FROM addresses; // Exclude column. SELECT * REPLACE (lower(city) AS city) FROM addresses; // Replace column. SELECT COLUMNS('number\d+') FROM addresses; // Regex column selection. SELECT min(COLUMNS(*)) FROM addresses; // Function on columns. "Column Name": Select columns with spaces. Star Expressions: Expands to columns in FROM clause. DISTINCT Clause: Returns unique rows. Expensive. DISTINCT ON (expr): One row per unique value in expr. Requires ORDER BY for consistent results. Aggregates: Combine rows into single value. Requires GROUP BY for non-aggregate expressions. Window Functions: Computes values relative to other rows. Requires OVER clause. unnest(array/struct): Removes one level of nesting. Set Operations: Combine queries. UNION [ALL], INTERSECT [ALL], EXCEPT [ALL]. ALL variants use bag semantics (duplicates allowed). UNION: Combines rows from multiple queries. Requires same number of columns. Implicit casting. Uses column names from first query. UNION ALL: Returns all rows without duplicate elimination. UNION [ALL] BY NAME: Joins columns by name. Does not require same number of columns. Missing columns filled with NULL. INTERSECT: Selects rows in both queries. INTERSECT ALL: Returns duplicates. EXCEPT: Selects rows only in the left query. EXCEPT ALL: Uses bag semantics. unnest(list/struct, recursive := BOOL, max_depth := INT): Unnests lists or structs. Recursive unnesting supported. When unnesting lists with scalar expressions, those expressions are repeated. Empty list/NULL -> zero elements. Combining with generate_subscripts allows tracking list positions. VALUES: Specifies fixed number of rows. Can be a standalone statement, part of FROM clause, or input to INSERT INTO. Example: VALUES ('Amsterdam', 1), ('London', 2). WHERE clause filters data. SELECT * FROM table_name WHERE id = 3; SELECT * FROM table_name WHERE name ILIKE '%mark%'; SELECT * FROM table_name WHERE id = 3 OR id = 7; WINDOW clause: Specifies named windows for use in window functions to avoid repetition. Syntax: WINDOW window_name AS (window_definition) WITH clause: Defines Common Table Expressions (CTEs). CTEs can be recursive. CTE materialization: AS MATERIALIZED / AS NOT MATERIALIZED. Recursive CTEs: WITH RECURSIVE. Example: WITH RECURSIVE FibonacciNumbers (RecursionDepth, FibonacciNumber, NextNumber) AS ( SELECT 0, 0, 1 UNION ALL SELECT fib.RecursionDepth + 1, fib.NextNumber, fib.FibonacciNumber + fib.NextNumber FROM FibonacciNumbers fib WHERE fib.RecursionDepth + 1 < 10 ) SELECT fn.RecursionDepth, fn.FibonacciNumber FROM FibonacciNumbers fn; Limitations: No mutually recursive CTEs. SQL SAMPLE: Random data subset. Methods: reservoir (exact rows), bernoulli, system (percentage). TABLESAMPLE: sample before FROM. USING SAMPLE: sample after FROM. Default: reservoir/system based on size type. ALTER TABLE: Modifies existing table schema. RENAME TABLE: Renames table. ALTER TABLE integers RENAME TO integers_old; RENAME COLUMN: Renames column. ALTER TABLE integers RENAME i TO ii; ADD COLUMN: Adds column with optional default. ALTER TABLE integers ADD COLUMN k INTEGER DEFAULT 10; DROP COLUMN: Removes column. Requires no indexes or multi-column check constraints. ALTER TABLE integers DROP k; ALTER TYPE: Changes column type using optional USING expression for conversion. ALTER TABLE integers ALTER i TYPE VARCHAR USING concat(i, '_', j); SET/DROP DEFAULT: Modifies column default value. ALTER TABLE integers ALTER COLUMN i SET DEFAULT 10; ADD PRIMARY KEY: Adds primary key. ALTER TABLE integers ADD PRIMARY KEY (i); Errors: Dependency Error if indexes exist. ADD/DROP CONSTRAINT: Not supported. ALTER VIEW changes a view's schema. ALTER VIEW v1 RENAME TO v2;. Respects transactional semantics. Dependent views not automatically updated. ANALYZE: Recomputes table statistics for join order optimization. Usage: ANALYZE. ATTACH/DETACH Statements: `ATTACH 'file' [AS alias] [(READ_ONLY, BLOCK_SIZE size, TYPE type)]`: attach database file. `DETACH alias`: detach database. `SHOW DATABASES`: show attached. `USE alias`: set default database. Options: `READ_ONLY`, `BLOCK_SIZE`, `TYPE (DUCKDB, SQLITE)`. Transaction: single write database. CALL Statement: `CALL table_function()`: invoke table function, return results. Example: `CALL duckdb_functions();` CHECKPOINT: Synchronizes WAL data to the database file. FORCE CHECKPOINT: Aborts transactions and executes checkpoint. COMMENT ON: Add metadata to catalog entries. Syntax: COMMENT ON TABLE table_name IS 'comment'; (TABLE, COLUMN, VIEW, INDEX, SEQUENCE, TYPE, MACRO, MACRO TABLE). Unset comment: COMMENT ON TABLE table_name IS NULL;. Read comments: SELECT comment FROM duckdb_tables(); (duckdb_columns, duckdb_views etc.). Limitations: No schema/database comments, no comments on objects with dependencies. COPY: Import/export data between DuckDB and files. FROM: import data to table from file (CSV, PARQUET, JSON). TO: export table/query result to file (CSV, PARQUET, JSON). Options: FORMAT, DELIMITER, HEADER, COMPRESSION, etc. FROM DATABASE: copy database content to another. SCHEMA option: copy schema only. Limitation: no table-to-table copy (use INSERT INTO). CREATE INDEX: Create index on table columns. Compound indexes supported, unidimensional only. CREATE UNIQUE INDEX name ON table (column): unique index. CREATE INDEX name ON table (column): non-unique index. CREATE INDEX name ON table (col1, col2): compound index. CREATE INDEX name ON table ((expression)): index on expression. DROP INDEX name: remove index. DROP INDEX IF EXISTS name: remove if exists. CREATE MACRO: Creates a scalar or table macro (function). Macro contains single SELECT, accepts parameters. Scalar Macro: CREATE MACRO name(params) AS expression; Returns single value. Table Macro: CREATE MACRO name(params) AS TABLE select_statement; Returns a table. Temporary Macro: Only usable within the same connection. CREATE TEMP MACRO. Overloading: CREATE MACRO name(params) AS expr, (params) AS expr; Named Parameters: Default parameters must be named when invoked. CREATE MACRO add_default(a, b := 5) AS a + b; SELECT add_default(40, b := 2) AS x; Limitations: Positional parameters can only be used positionally. Subquery macros cannot be invoked in table functions. Overloads have to be set at creation. CREATE SCHEMA statement: Creates a schema in the catalog. Default schema is main. Examples: -CREATE SCHEMA s1; -CREATE SCHEMA IF NOT EXISTS s2; -CREATE TABLE s1.t (id INTEGER PRIMARY KEY, other_id INTEGER); -SELECT * FROM s1.t s1t, s2.t s2t WHERE s1t.other_id = s2t.id; CREATE SECRET: Creates new secret in Secrets Manager. Syntax for CREATE SECRET, DROP SECRET. CREATE SEQUENCE creates a sequence number generator. CREATE SEQUENCE serial START 101; CREATE SEQUENCE serial START WITH 1 INCREMENT BY 2; CREATE SEQUENCE serial START WITH 99 INCREMENT BY -1 MAXVALUE 99; CREATE SEQUENCE serial START WITH 1 MAXVALUE 10 CYCLE; nextval('serial'): gets next sequence value. currval('serial'): gets current sequence value (after nextval called). CYCLE: allows wrap-around. INCREMENT BY: value added to current. MAXVALUE/MINVALUE: limits. START WITH: starting value. CREATE TABLE table_name (column_name data_type [constraints]). Constraints: PRIMARY KEY, CHECK (expression), FOREIGN KEY (column) REFERENCES table(column), NOT NULL, UNIQUE. CREATE TEMP TABLE: Session-scoped. CREATE OR REPLACE TABLE: Overwrites existing table. CREATE TABLE IF NOT EXISTS: Creates only if table does not exist. CREATE TABLE AS SELECT (CTAS): Creates table from a query. Example: CREATE TABLE t1 AS SELECT * FROM read_csv('file.csv'). Generated Columns: column_name data_type GENERATED ALWAYS AS (expression) VIRTUAL. Only VIRTUAL supported. CREATE TYPE name AS ENUM ('val1', 'val2'); creates an ENUM type. CREATE TYPE name AS STRUCT(k INTEGER, l VARCHAR); creates a STRUCT type. CREATE TYPE name AS UNION(number INTEGER, string VARCHAR); creates a UNION type. CREATE TYPE alias AS INTEGER; creates a type alias. CREATE VIEW: Defines a view. CREATE OR REPLACE VIEW: Replaces if exists. CREATE VIEW v1(a) AS SELECT 42; SELECT sql FROM duckdb_views() WHERE view_name = 'v1'; Views are not materialized. DELETE Statement: Removes rows from table. DELETE FROM tbl WHERE i = 2; DELETE FROM tbl; (all rows) TRUNCATE tbl; (alias for deleting all rows) WHERE clause: Only rows where clause is true are deleted. USING clause: Allows deleting based on other tables/subqueries. Space is reclaimed on CHECKPOINT. VACUUM currently does not reclaim space. DESCRIBE Statement: Shows schema of table/view/query. Usage: DESCRIBE tbl; DESCRIBE SELECT * FROM tbl; SHOW is alias for DESCRIBE. DROP statement: Removes catalog entry. Syntax: DROP TABLE tbl; DROP VIEW v1; DROP FUNCTION fn; DROP INDEX idx; DROP SCHEMA sch; DROP SEQUENCE seq; DROP MACRO mcr; DROP MACRO TABLE mt; DROP TYPE typ. Clauses: RESTRICT, CASCADE. CASCADE drops dependent objects. EXPORT DATABASE command: Exports database content to a directory. IMPORT DATABASE command: Reads the exported content. Examples: -EXPORT DATABASE 'target_directory'; -EXPORT DATABASE 'target_directory' (FORMAT CSV, DELIMITER '|'); -EXPORT DATABASE 'target_directory' (FORMAT PARQUET); -EXPORT DATABASE 'target_directory' (FORMAT PARQUET, COMPRESSION ZSTD, ROW_GROUP_SIZE 100_000); -IMPORT DATABASE 'source_directory'; or PRAGMA import_database('source_directory'); Directory Structure: target_directory/schema.sql, target_directory/load.sql, target_directory/t_1.csv, ... schema.sql: CREATE SCHEMA, TABLE, VIEW, SEQUENCE commands. load.sql: COPY statements to load data. INSERT Statement: Inserts data into table. Syntax: INSERT INTO table VALUES (...); INSERT INTO table SELECT .... Column order: BY POSITION BY NAME. ON CONFLICT [conflict_target] DO NOTHING/DO UPDATE SET ... [WHERE condition]. DO NOTHING: ignore conflict. DO UPDATE: update row, use EXCLUDED. INSERT OR IGNORE/REPLACE INTO: shortcuts. Limitation: ON CONFLICT DO UPDATE for single conflict per key. RETURNING clause: return inserted rows, e.g. RETURNING *. INSTALL extension_name [FROM community] install extension LOAD extension_name load installed extension Statements Overview: Lists available SQL statements. PIVOT statement: Transforms distinct column values into separate columns. Implements SQL Standard PIVOT and simplified PIVOT syntax. UNPIVOT is the inverse. Simplified Syntax: PIVOT dataset ON columns USING values GROUP BY rows ORDER BY columns_with_order_directions LIMIT number_of_rows; ON, USING, GROUP BY are optional, but not all omittable. -ON clause: Column(s) to split. -USING clause: Aggregates values, defaults to count(*). Does not support FILTER clauses. first aggregate function pivots text column. -GROUP BY clause: Includes columns, further aggregates. -IN expression: Filters values in ON clause. -Multiple ON columns: Cartesian product of distinct values. Use expressions for present value combinations. -Multiple USING expressions: Use aliases (AS) for cleaner naming. -Can be used within SELECT (CTE or subquery). SQL Standard Syntax: SELECT * FROM dataset PIVOT (values FOR column_1 IN (in_list) column_2 IN (in_list) ... GROUP BY rows); IN clause required for each pivoted column. Limitation: PIVOT only accepts aggregate functions; use COLUMNS expression for workarounds. EXPLAIN ⟨query⟩: Shows the query plan without execution. EXPLAIN ANALYZE ⟨query⟩: Executes the query, shows actual cardinalities and execution time for each operator. SELECT: Retrieves rows. SELECT * FROM tbl; SELECT i, sum(j) FROM tbl GROUP BY i; SELECT #1, #3 FROM tbl; SELECT DISTINCT city FROM addresses. SELECT d FROM (SELECT 1 AS a, 2 AS b) d. Clauses: SELECT, FROM, SAMPLE, WHERE, GROUP BY, HAVING, WINDOW, QUALIFY, ORDER BY, LIMIT, OFFSET. SET option = value; modifies a configuration option. RESET option; resets option to default. SELECT current_setting('option'); retrieves option value. Scopes: GLOBAL (entire instance), SESSION (current session). SET GLOBAL search_path = 'db1,db2'; SET SESSION default_collation = 'nocase'; SET VARIABLE statement defines SQL-level variables. SET VARIABLE my_var = value. Access variable: getvariable('my_var'). Overwrites existing variables. Data types supported. getvariable returns NULL if undefined. RESET VARIABLE my_var: unsets variable. SUMMARIZE statement: Returns summary statistics for a table, view, or query. Usage: SUMMARIZE tbl; SUMMARIZE SELECT * FROM tbl; Transaction Management: BEGIN TRANSACTION starts transaction. COMMIT commits transaction. ROLLBACK/ABORT aborts transaction. Errors if not in active transaction. Example: CREATE TABLE person (name VARCHAR, age BIGINT); BEGIN TRANSACTION; INSERT INTO person VALUES ('Ada', 52); COMMIT; table will contain Ada. UNPIVOT statement stacks columns into NAME and VALUE columns. Simplified syntax: UNPIVOT dataset ON columns INTO NAME name_col VALUE value_col. COLUMNS expression for dynamic column selection. Multiple value columns supported. Used in SELECT, CTE, subqueries. Expressions allowed within UNPIVOT. SQL Standard syntax: FROM dataset UNPIVOT (value_cols FOR name_col IN columns). Supports dynamic columns and multiple value columns. UPDATE: Modifies table row values. UPDATE tbl SET col = value WHERE condition. Updates can use data from other tables via FROM or subqueries. Supports UPDATE ... FROM ... WHERE ... and UPDATE ... SET = (SELECT ...). USE statement: Selects default database and schema. USE database; USE database.schema; VACUUM Statement. VACUUM (no-op). VACUUM ANALYZE recomputes statistics. VACUUM ANALYZE table(column) for specific column. VACUUM FULL not supported. Does not reclaim space.